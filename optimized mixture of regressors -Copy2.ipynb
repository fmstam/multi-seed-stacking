{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the **[30 Days of ML competition](https://www.kaggle.com/c/30-days-of-ml/overview)**!  In this notebook, you'll learn how to make your first submission.\n",
    "\n",
    "Before getting started, make your own editable copy of this notebook by clicking on the **Copy and Edit** button.\n",
    "\n",
    "# Step 1: Import helpful libraries\n",
    "\n",
    "We begin by importing the libraries we'll need.  Some of them will be familiar from the **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course and the **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:09.725137Z",
     "iopub.status.busy": "2021-08-16T22:55:09.724708Z",
     "iopub.status.idle": "2021-08-16T22:55:09.73297Z",
     "shell.execute_reply": "2021-08-16T22:55:09.731277Z",
     "shell.execute_reply.started": "2021-08-16T22:55:09.725102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Familiar imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "\n",
    "\n",
    "# For ordinal encoding categorical variables, splitting data, pipeline, and so on\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, PowerTransformer, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# For training random forest model\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# base\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the data\n",
    "\n",
    "Next, we'll load the training and test data.  \n",
    "\n",
    "We set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:10.592447Z",
     "iopub.status.busy": "2021-08-16T22:55:10.591978Z",
     "iopub.status.idle": "2021-08-16T22:55:14.91458Z",
     "shell.execute_reply": "2021-08-16T22:55:14.912747Z",
     "shell.execute_reply.started": "2021-08-16T22:55:10.592407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.527335</td>\n",
       "      <td>0.230599</td>\n",
       "      <td>-0.118039</td>\n",
       "      <td>0.405965</td>\n",
       "      <td>0.497053</td>\n",
       "      <td>0.668060</td>\n",
       "      <td>1.058443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.460926</td>\n",
       "      <td>0.214003</td>\n",
       "      <td>-0.069309</td>\n",
       "      <td>0.310494</td>\n",
       "      <td>0.427903</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.887253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.490498</td>\n",
       "      <td>0.253346</td>\n",
       "      <td>-0.056104</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.502462</td>\n",
       "      <td>0.647512</td>\n",
       "      <td>1.034704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>0.219199</td>\n",
       "      <td>0.130676</td>\n",
       "      <td>0.329783</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.664451</td>\n",
       "      <td>1.039560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.491654</td>\n",
       "      <td>0.240074</td>\n",
       "      <td>0.255908</td>\n",
       "      <td>0.284188</td>\n",
       "      <td>0.390470</td>\n",
       "      <td>0.696599</td>\n",
       "      <td>1.055424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.510526</td>\n",
       "      <td>0.228232</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>0.354141</td>\n",
       "      <td>0.488865</td>\n",
       "      <td>0.669625</td>\n",
       "      <td>1.067649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.467476</td>\n",
       "      <td>0.210331</td>\n",
       "      <td>-0.224689</td>\n",
       "      <td>0.342873</td>\n",
       "      <td>0.429383</td>\n",
       "      <td>0.573383</td>\n",
       "      <td>1.111552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.537119</td>\n",
       "      <td>0.218140</td>\n",
       "      <td>0.203763</td>\n",
       "      <td>0.355825</td>\n",
       "      <td>0.504661</td>\n",
       "      <td>0.703441</td>\n",
       "      <td>1.032837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.498456</td>\n",
       "      <td>0.239920</td>\n",
       "      <td>-0.260275</td>\n",
       "      <td>0.332486</td>\n",
       "      <td>0.439151</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>1.040229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.474872</td>\n",
       "      <td>0.218007</td>\n",
       "      <td>0.117896</td>\n",
       "      <td>0.306874</td>\n",
       "      <td>0.434620</td>\n",
       "      <td>0.614333</td>\n",
       "      <td>0.982922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.474492</td>\n",
       "      <td>0.255949</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>0.276017</td>\n",
       "      <td>0.459975</td>\n",
       "      <td>0.691579</td>\n",
       "      <td>1.055960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.473216</td>\n",
       "      <td>0.222022</td>\n",
       "      <td>0.052608</td>\n",
       "      <td>0.308151</td>\n",
       "      <td>0.433812</td>\n",
       "      <td>0.642057</td>\n",
       "      <td>1.071444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.494561</td>\n",
       "      <td>0.247292</td>\n",
       "      <td>-0.074208</td>\n",
       "      <td>0.289074</td>\n",
       "      <td>0.422887</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>0.975035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.508273</td>\n",
       "      <td>0.222950</td>\n",
       "      <td>0.151050</td>\n",
       "      <td>0.300669</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.758447</td>\n",
       "      <td>0.905992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>8.241979</td>\n",
       "      <td>0.746555</td>\n",
       "      <td>0.140329</td>\n",
       "      <td>7.742071</td>\n",
       "      <td>8.191373</td>\n",
       "      <td>8.728634</td>\n",
       "      <td>10.411992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std       min       25%       50%       75%  \\\n",
       "cont0   300000.0  0.527335  0.230599 -0.118039  0.405965  0.497053  0.668060   \n",
       "cont1   300000.0  0.460926  0.214003 -0.069309  0.310494  0.427903  0.615113   \n",
       "cont2   300000.0  0.490498  0.253346 -0.056104  0.300604  0.502462  0.647512   \n",
       "cont3   300000.0  0.496689  0.219199  0.130676  0.329783  0.465026  0.664451   \n",
       "cont4   300000.0  0.491654  0.240074  0.255908  0.284188  0.390470  0.696599   \n",
       "cont5   300000.0  0.510526  0.228232  0.045915  0.354141  0.488865  0.669625   \n",
       "cont6   300000.0  0.467476  0.210331 -0.224689  0.342873  0.429383  0.573383   \n",
       "cont7   300000.0  0.537119  0.218140  0.203763  0.355825  0.504661  0.703441   \n",
       "cont8   300000.0  0.498456  0.239920 -0.260275  0.332486  0.439151  0.606056   \n",
       "cont9   300000.0  0.474872  0.218007  0.117896  0.306874  0.434620  0.614333   \n",
       "cont10  300000.0  0.474492  0.255949  0.048732  0.276017  0.459975  0.691579   \n",
       "cont11  300000.0  0.473216  0.222022  0.052608  0.308151  0.433812  0.642057   \n",
       "cont12  300000.0  0.494561  0.247292 -0.074208  0.289074  0.422887  0.714502   \n",
       "cont13  300000.0  0.508273  0.222950  0.151050  0.300669  0.472400  0.758447   \n",
       "target  300000.0  8.241979  0.746555  0.140329  7.742071  8.191373  8.728634   \n",
       "\n",
       "              max  \n",
       "cont0    1.058443  \n",
       "cont1    0.887253  \n",
       "cont2    1.034704  \n",
       "cont3    1.039560  \n",
       "cont4    1.055424  \n",
       "cont5    1.067649  \n",
       "cont6    1.111552  \n",
       "cont7    1.032837  \n",
       "cont8    1.040229  \n",
       "cont9    0.982922  \n",
       "cont10   1.055960  \n",
       "cont11   1.071444  \n",
       "cont12   0.975035  \n",
       "cont13   0.905992  \n",
       "target  10.411992  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "\n",
    "# Preview the data\n",
    "train.head()\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell separates the target (which we assign to `y`) from the training features (which we assign to `features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:14.916952Z",
     "iopub.status.busy": "2021-08-16T22:55:14.916515Z",
     "iopub.status.idle": "2021-08-16T22:55:14.984676Z",
     "shell.execute_reply": "2021-08-16T22:55:14.98316Z",
     "shell.execute_reply.started": "2021-08-16T22:55:14.916916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat0</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat1</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat2</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat3</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat4</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat5</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat6</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat7</th>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat8</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat9</th>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>0.20147</td>\n",
       "      <td>0.743068</td>\n",
       "      <td>0.742708</td>\n",
       "      <td>0.429551</td>\n",
       "      <td>1.05829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>-0.0148218</td>\n",
       "      <td>0.367411</td>\n",
       "      <td>0.310383</td>\n",
       "      <td>0.620998</td>\n",
       "      <td>0.367492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>0.669699</td>\n",
       "      <td>1.02161</td>\n",
       "      <td>-0.0126728</td>\n",
       "      <td>0.577942</td>\n",
       "      <td>-0.0523886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>0.136278</td>\n",
       "      <td>0.365798</td>\n",
       "      <td>0.576957</td>\n",
       "      <td>0.28061</td>\n",
       "      <td>0.232407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>0.610706</td>\n",
       "      <td>0.276853</td>\n",
       "      <td>0.285074</td>\n",
       "      <td>0.284667</td>\n",
       "      <td>0.287595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.533087</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.66898</td>\n",
       "      <td>0.686964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>0.160266</td>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.420667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.732948</td>\n",
       "      <td>0.648182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>0.38947</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.679618</td>\n",
       "      <td>0.684501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.956692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.34601</td>\n",
       "      <td>1.00077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.71461</td>\n",
       "      <td>0.776742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.54015</td>\n",
       "      <td>0.625849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>0.86985</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>0.763846</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>0.250823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id              1         2          3         4          6\n",
       "cat0            B         B          A         B          A\n",
       "cat1            B         B          A         B          A\n",
       "cat2            B         A          A         A          A\n",
       "cat3            C         A          C         C          C\n",
       "cat4            B         B          B         B          B\n",
       "cat5            B         D          D         D          D\n",
       "cat6            A         A          A         A          A\n",
       "cat7            E         F          D         E          E\n",
       "cat8            C         A          A         C          A\n",
       "cat9            N         O          F         K          N\n",
       "cont0     0.20147  0.743068   0.742708  0.429551    1.05829\n",
       "cont1  -0.0148218  0.367411   0.310383  0.620998   0.367492\n",
       "cont2    0.669699   1.02161 -0.0126728  0.577942 -0.0523886\n",
       "cont3    0.136278  0.365798   0.576957   0.28061   0.232407\n",
       "cont4    0.610706  0.276853   0.285074  0.284667   0.287595\n",
       "cont5    0.400361  0.533087   0.650609   0.66898   0.686964\n",
       "cont6    0.160266  0.558922   0.375348  0.239061   0.420667\n",
       "cont7    0.310921  0.516294   0.902567  0.732948   0.648182\n",
       "cont8     0.38947  0.594928   0.555205  0.679618   0.684501\n",
       "cont9    0.267559  0.341439   0.843531  0.574844   0.956692\n",
       "cont10   0.237281  0.906013   0.748809   0.34601    1.00077\n",
       "cont11   0.377873  0.921701   0.620126   0.71461   0.776742\n",
       "cont12   0.322401  0.261975   0.541474   0.54015   0.625849\n",
       "cont13    0.86985  0.465083   0.763846  0.280682   0.250823"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate target from features\n",
    "y = train['target']\n",
    "features = train.drop(['target'], axis=1)\n",
    "\n",
    "# Preview features\n",
    "features.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the data\n",
    "\n",
    "Next, we'll need to handle the categorical columns (`cat0`, `cat1`, ... `cat9`).  \n",
    "\n",
    "In the **[Categorical Variables lesson](https://www.kaggle.com/alexisbcook/categorical-variables)** in the Intermediate Machine Learning course, you learned several different ways to encode categorical variables in a dataset.  In this notebook, we'll use ordinal encoding and save our encoded features as new variables `X` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_poly_features(train, test, cols=None, concate=True, poly_degree=2):\n",
    "    \n",
    "    if cols is  None:\n",
    "        cols = train.columns\n",
    "     \n",
    "    columns = train[cols].columns\n",
    "    poly = PolynomialFeatures(poly_degree)\n",
    "    poly_train = pd.DataFrame(poly.fit_transform(train[cols]), index=train.index)\n",
    "    poly_test = pd.DataFrame(poly.transform(test[cols]), index=test.index)\n",
    "    \n",
    "    # stamp these columns\n",
    "    poly_train = poly_train.add_prefix('poly_')\n",
    "    poly_test = poly_test.add_prefix('poly_')\n",
    "    \n",
    "    if concate:\n",
    "        train = pd.concat([train, poly_train], axis=1)\n",
    "        test = pd.concat([test, poly_test], axis=1)\n",
    "        \n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:17.707975Z",
     "iopub.status.busy": "2021-08-16T22:55:17.7076Z",
     "iopub.status.idle": "2021-08-16T22:55:19.670568Z",
     "shell.execute_reply": "2021-08-16T22:55:19.669219Z",
     "shell.execute_reply.started": "2021-08-16T22:55:17.707941Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of categorical columns\n",
    "object_cols_long = [col for col in features.columns if 'cat' in col]\n",
    "cont_cols = [col for col in features.columns if 'con' in col]\n",
    "\n",
    "X = features.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "# cols = ['cont0', 'cont3', 'cont9']\n",
    "# add poly features\n",
    "# X, X_test = add_poly_features(X, X_test, cols)\n",
    "\n",
    "\n",
    "# encoding\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X[object_cols_long] = ordinal_encoder.fit_transform(X[object_cols_long])\n",
    "X_test[object_cols_long] = ordinal_encoder.transform(X_test[object_cols_long])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we break off a validation set from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:29.309502Z",
     "iopub.status.busy": "2021-08-16T22:55:29.309037Z",
     "iopub.status.idle": "2021-08-16T22:55:29.774149Z",
     "shell.execute_reply": "2021-08-16T22:55:29.772853Z",
     "shell.execute_reply.started": "2021-08-16T22:55:29.309468Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225000, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.1: Predict using Stacking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def cv_score(model, X, y, scoring_method=\"neg_mean_squared_error\", shuffle=True, k=5):\n",
    "    \n",
    "    kfolds = KFold(n_splits=k, \n",
    "                  shuffle=shuffle,\n",
    "                  random_state=42)\n",
    "    \n",
    "    return cross_val_score(model, \n",
    "                            X, y, \n",
    "                            scoring=scoring_method,\n",
    "                            cv = kfolds)\n",
    "\n",
    "def rmse_score(model, X_train, y_train, X_valid, y_valid, **kwargs):\n",
    "        model.fit(X_train, y_train, **kwargs)\n",
    "        predictions = model.predict(X_valid)\n",
    "        \n",
    "        return mean_squared_error(predictions, y_valid, squared=False)\n",
    "\n",
    "   \n",
    "def get_oof_predictions(model, X, y, X_test,\n",
    "                        model_name=None, \n",
    "                        stacking_level=1,\n",
    "                        k=12, \n",
    "                        shuffle=True, \n",
    "                        use_eval_set=False, \n",
    "                        multi=False, \n",
    "                        store=True, **kwargs):\n",
    "    \n",
    "    \"\"\" out of folds OOFs calculations\n",
    "    Not the best practice must be splited into two or more functions or an OOP class would be better.\n",
    "    \"\"\"\n",
    "    \n",
    "    kfolds = KFold(n_splits=k, \n",
    "                  shuffle=shuffle,\n",
    "                  random_state=42)\n",
    "    \n",
    "    test_predictions = 0\n",
    "    t_valid_predictions = np.zeros_like(np.array(y))\n",
    "    valid_mean_score = [] \n",
    "    \n",
    "    for fold, (train_index, valid_index) in enumerate(kfolds.split(X)):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        if multi:\n",
    "            for m in model.models:\n",
    "                print('cloning ' + m.__class__.__name__)\n",
    "                m = clone(m)\n",
    "                \n",
    "        else:\n",
    "             model_ = clone(model)\n",
    "                \n",
    "        if use_eval_set:\n",
    "            model_.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], **kwargs)\n",
    "        else:\n",
    "            model_.fit(X_train, y_train, **kwargs)\n",
    "        \n",
    "        # validation score\n",
    "        valid_predications = model_.predict(X_valid)\n",
    "        score = mean_squared_error(valid_predications, y_valid, squared=False)\n",
    "        valid_mean_score.append(score)\n",
    "        \n",
    "        t_valid_predictions[valid_index] = valid_predications\n",
    "        # test predictions\n",
    "        test_predictions += model_.predict(X_test) / k\n",
    "        \n",
    "        print('Fold:{} score:{:.4f}'.format(fold + 1, score))\n",
    "        \n",
    "    print('average score:{:.4f} ({:.4f})'.format(np.mean(valid_mean_score), np.std(valid_mean_score) ))\n",
    "    \n",
    "\n",
    "    # store them\n",
    "    \n",
    "    if model_name is None:\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "    test_df = pd.DataFrame({'Id': X_test.index,\n",
    "                       model_name: test_predictions})\n",
    "    valid_df = pd.DataFrame({'Id': X.index,\n",
    "                       model_name: t_valid_predictions})\n",
    "\n",
    "        \n",
    "    test_df.to_csv( 'level_{}/{}_{}_test.csv'.format(stacking_level, model_name, k),\n",
    "                    index=False)\n",
    "    valid_df.to_csv('level_{}/{}_{}_valid.csv'.format(stacking_level, model_name, k), \n",
    "                    index=False)\n",
    "    return test_predictions, t_valid_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramaters: # to be tuned later\n",
    "\n",
    "# extra-tree\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "# random forest\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.00005, random_state=1))\n",
    "\n",
    "# Elastic net\n",
    "e_net = make_pipeline(RobustScaler(), ElasticNet(alpha=0.00005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "# KNeighborsRegressor\n",
    "knn = make_pipeline(RobustScaler(), KNeighborsRegressor())\n",
    "\n",
    "# extra-tree\n",
    "extree = ExtraTreesRegressor(**et_params)\n",
    "\n",
    "# random forest\n",
    "rfr = RandomForestRegressor(**rf_params)\n",
    "\n",
    "# # KR\n",
    "# KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=1, coef0=2.5)\n",
    "\n",
    "# # gradient boosing\n",
    "# gb = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, \n",
    "#                                    max_depth=4, max_features='sqrt',\n",
    "#                                    min_samples_leaf=15, min_samples_split=10, \n",
    "#                                    loss='huber', random_state =5)\n",
    "\n",
    "xgb_params = {'n_estimators': 10000,\n",
    "              'learning_rate': 0.35,\n",
    "              'subsample': 0.926,\n",
    "              'colsample_bytree': 0.84,\n",
    "              'max_depth': 2,\n",
    "              'booster': 'gbtree', \n",
    "              'reg_lambda': 35.1,\n",
    "              'reg_alpha': 34.9,\n",
    "              'random_state': 42,\n",
    "              'n_jobs': -1}\n",
    "\n",
    "xgb =  XGBRegressor(**xgb_params)\n",
    "\n",
    "\n",
    "catb = CatBoostRegressor(iterations=6800,\n",
    "                  learning_rate=0.93,\n",
    "                  loss_function=\"RMSE\",\n",
    "                  random_state=42,\n",
    "                  verbose=0,\n",
    "                  thread_count=4,\n",
    "                  depth=1,\n",
    "                  l2_leaf_reg=3.28)\n",
    "\n",
    "SEED = 7770777\n",
    "params_lgb = {\n",
    "    \"n_estimators\": 10000,   \n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.007899156646724397,\n",
    "    \"num_leaves\": 77,\n",
    "    \"max_depth\": 77,\n",
    "    \"feature_fraction\": 0.2256038826485174,\n",
    "    \"bagging_fraction\": 0.7705303688019942,\n",
    "    \"min_child_samples\": 290,\n",
    "    \"reg_alpha\": 9.562925363678952,\n",
    "    \"reg_lambda\": 9.355810045480153,\n",
    "    \"max_bin\": 772,\n",
    "    \"min_data_per_group\": 177,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"cat_smooth\": 96,\n",
    "    \"cat_l2\": 17,\n",
    "    \"verbosity\": -1,\n",
    "    \"bagging_seed\": SEED,\n",
    "    \"feature_fraction_seed\": SEED,\n",
    "    \"verbose_eval\":1000,\n",
    "    \"seed\": SEED\n",
    "}\n",
    "\n",
    "lgb = LGBMRegressor(**params_lgb)\n",
    "\n",
    "\n",
    "models = [lasso, e_net, extree, rfr, gb, xgb, catb, lgb]\n",
    "# lasso and ElasticNet are included in pipelines \n",
    "names =['Lasso', 'ElasticNet']\n",
    "names = names + [model.__class__.__name__ for model in models[2:]]\n",
    "\n",
    "selected_models = dict(zip(names, models))\n",
    "#selected_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach I am going to run k-folds using each model and average the rest results among folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7434\n",
      "Fold:2 score:0.7340\n",
      "Fold:3 score:0.7360\n",
      "Fold:4 score:0.7370\n",
      "Fold:5 score:0.7451\n",
      "Fold:6 score:0.7421\n",
      "Fold:7 score:0.7342\n",
      "Fold:8 score:0.7404\n",
      "Fold:9 score:0.7352\n",
      "Fold:10 score:0.7421\n",
      "Fold:11 score:0.7447\n",
      "Fold:12 score:0.7363\n",
      "average score:0.7392 (0.0040)\n"
     ]
    }
   ],
   "source": [
    "lasso_test_results, lasso_valid_results = get_oof_predictions(lasso, X, y, X_test, model_name='lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7434\n",
      "Fold:2 score:0.7340\n",
      "Fold:3 score:0.7360\n",
      "Fold:4 score:0.7370\n",
      "Fold:5 score:0.7451\n",
      "Fold:6 score:0.7421\n",
      "Fold:7 score:0.7342\n",
      "Fold:8 score:0.7405\n",
      "Fold:9 score:0.7352\n",
      "Fold:10 score:0.7421\n",
      "Fold:11 score:0.7447\n",
      "Fold:12 score:0.7363\n",
      "average score:0.7392 (0.0040)\n"
     ]
    }
   ],
   "source": [
    "enet_test_results, enet_valid_results = get_oof_predictions(e_net, X, y, X_test, model_name='Enet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7191\n",
      "Fold:2 score:0.7138\n",
      "Fold:3 score:0.7136\n",
      "Fold:4 score:0.7155\n",
      "Fold:5 score:0.7210\n",
      "Fold:6 score:0.7201\n",
      "Fold:7 score:0.7142\n",
      "Fold:8 score:0.7187\n",
      "Fold:9 score:0.7140\n",
      "Fold:10 score:0.7200\n",
      "Fold:11 score:0.7200\n",
      "Fold:12 score:0.7120\n",
      "average score:0.7168 (0.0031)\n"
     ]
    }
   ],
   "source": [
    "xgb_test_results, xgb_valid_results = get_oof_predictions(xgb, X, y, X_test, use_eval_set=True,\n",
    "                   early_stopping_rounds=200,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7199\n",
      "Fold:2 score:0.7138\n",
      "Fold:3 score:0.7141\n",
      "Fold:4 score:0.7164\n",
      "Fold:5 score:0.7213\n",
      "Fold:6 score:0.7203\n",
      "Fold:7 score:0.7138\n",
      "Fold:8 score:0.7192\n",
      "Fold:9 score:0.7142\n",
      "Fold:10 score:0.7205\n",
      "Fold:11 score:0.7211\n",
      "Fold:12 score:0.7131\n",
      "average score:0.7173 (0.0032)\n"
     ]
    }
   ],
   "source": [
    "lgb_test_results, lgb_valid_results = get_oof_predictions(lgb, X, y, X_test, use_eval_set=True,\n",
    "                   early_stopping_rounds=200,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7209\n",
      "Fold:2 score:0.7145\n",
      "Fold:3 score:0.7149\n",
      "Fold:4 score:0.7175\n",
      "Fold:5 score:0.7224\n",
      "Fold:6 score:0.7209\n",
      "Fold:7 score:0.7149\n",
      "Fold:8 score:0.7203\n",
      "Fold:9 score:0.7146\n",
      "Fold:10 score:0.7215\n",
      "Fold:11 score:0.7219\n",
      "Fold:12 score:0.7138\n",
      "average score:0.7182 (0.0033)\n"
     ]
    }
   ],
   "source": [
    "catb_test_results, catb_valid_results = get_oof_predictions(catb, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7396\n",
      "Fold:2 score:0.7313\n",
      "Fold:3 score:0.7334\n",
      "Fold:4 score:0.7348\n",
      "Fold:5 score:0.7421\n",
      "Fold:6 score:0.7399\n",
      "Fold:7 score:0.7316\n",
      "Fold:8 score:0.7382\n",
      "Fold:9 score:0.7327\n",
      "Fold:10 score:0.7397\n",
      "Fold:11 score:0.7418\n",
      "Fold:12 score:0.7336\n",
      "average score:0.7366 (0.0039)\n"
     ]
    }
   ],
   "source": [
    "extree_test_results, extree_valid_results = get_oof_predictions(extree, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7401\n",
      "Fold:2 score:0.7317\n",
      "Fold:3 score:0.7336\n",
      "Fold:4 score:0.7348\n",
      "Fold:5 score:0.7420\n",
      "Fold:6 score:0.7396\n",
      "Fold:7 score:0.7318\n",
      "Fold:8 score:0.7381\n",
      "Fold:9 score:0.7328\n",
      "Fold:10 score:0.7396\n",
      "Fold:11 score:0.7416\n",
      "Fold:12 score:0.7337\n",
      "average score:0.7366 (0.0038)\n"
     ]
    }
   ],
   "source": [
    "rfr_test_results, rfr_valid_results = get_oof_predictions(rfr, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet_12_valid.csv\n",
      "Lasso_12_valid.csv\n",
      "CatBoostRegressor_12_valid.csv\n",
      "RandomForestRegressor_12_valid.csv\n",
      "XGBRegressor_12_valid.csv\n",
      "ExtraTreesRegressor_12_valid.csv\n",
      "LGBMRegressor_12_valid.csv\n",
      "4\n",
      "ExtraTreesRegressor_12_test.csv\n",
      "CatBoostRegressor_12_test.csv\n",
      "LGBMRegressor_12_test.csv\n",
      "ElasticNet_12_test.csv\n",
      "XGBRegressor_12_test.csv\n",
      "Lasso_12_test.csv\n",
      "RandomForestRegressor_12_test.csv\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature</th>\n",
       "      <th>feature</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.457421</td>\n",
       "      <td>8.255680</td>\n",
       "      <td>8.419353</td>\n",
       "      <td>8.244644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.361938</td>\n",
       "      <td>8.315244</td>\n",
       "      <td>8.432220</td>\n",
       "      <td>8.293434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.222198</td>\n",
       "      <td>8.140362</td>\n",
       "      <td>8.180540</td>\n",
       "      <td>8.156236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.392812</td>\n",
       "      <td>8.279955</td>\n",
       "      <td>8.401962</td>\n",
       "      <td>8.284501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.278599</td>\n",
       "      <td>8.187986</td>\n",
       "      <td>8.133272</td>\n",
       "      <td>8.189441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature   feature   feature   feature\n",
       "Id                                        \n",
       "1   8.457421  8.255680  8.419353  8.244644\n",
       "2   8.361938  8.315244  8.432220  8.293434\n",
       "3   8.222198  8.140362  8.180540  8.156236\n",
       "4   8.392812  8.279955  8.401962  8.284501\n",
       "6   8.278599  8.187986  8.133272  8.189441"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generalized stacking\n",
    "\n",
    "import glob\n",
    "\n",
    "def read_results_set(pattern, \n",
    "                     models_names, \n",
    "                     index='id'):    \n",
    "    \"\"\"\n",
    "    Read files according the pattern in their name\n",
    "    \"\"\"\n",
    "    li = [] \n",
    "    for f in glob.glob(pattern):\n",
    "        file_name = f.split(os.sep)[1] # get file name only\n",
    "        print(file_name)\n",
    "        if file_name.lower().startswith(tuple(s.lower() for s in models_names)): # get only required models\n",
    "            df = pd.read_csv(f, index_col=0)\n",
    "            li.append(df)\n",
    "    \n",
    "                                   \n",
    "    print(len(li))    \n",
    "    return pd.concat(li, axis=1)\n",
    "                            \n",
    "\n",
    "# required results                            \n",
    "fold_id = 12\n",
    "folder ='level_1'\n",
    "                            \n",
    "                      \n",
    "models_pack = ['Lasso',\n",
    "               'ElasticNet', \n",
    "               'ExtraTreesRegressor', \n",
    "               'RandomForestRegressor', \n",
    "               'XGBRegressor', \n",
    "               'CatBoostRegressor', \n",
    "               'LGBMRegressor']\n",
    "\n",
    "level_1_models = ['RandomForestRegressor', \n",
    "                  'ExtraTreesRegressor',\n",
    "                  'XGBRegressor',\n",
    "                  'CatBoostRegressor'\n",
    "                  ]\n",
    "\n",
    "meta_regressor = 'LGBMRegressor'\n",
    "\n",
    "\n",
    "\n",
    "# new features \n",
    "X_train_ = read_results_set(pattern=f\"{folder}{os.sep}*{fold_id}_valid.csv\",\n",
    "                           models_names=level_1_models)\n",
    "X_test_ = read_results_set(pattern=f\"{folder}{os.sep}*{fold_id}_test.csv\",\n",
    "                          models_names=level_1_models)\n",
    "\n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = f\"{folder}*{fold_id}_valid\"\n",
    "glob.glob(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_stack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-15cd3adde6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_stack' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_.columns = [str(i) for i in range(len(X_train_.columns))]\n",
    "X_test_.columns = [str(i) for i in range(len(X_train_.columns))]\n",
    "#X_train_, X_test_ = add_poly_features(X_train_, X_test_, concate=True, poly_degree=2)\n",
    "#X_train_.drop(['poly_0', 'poly_1' ,'poly_2','poly_3', 'poly_4'], inplace =True, axis=1)\n",
    "#X_test_.drop(['poly_0', 'poly_1' ,'poly_2','poly_3', 'poly_4'], inplace =True, axis=1)\n",
    "# X_train_['q_3'] = pd.qcut(X_train_['3'], 35)\n",
    "# y_ = pd.cut(y, 5)\n",
    "# oe = LabelEncoder()\n",
    "# X_train_['q_3'] = oe.fit(y_).transform(X_train_['3'])\n",
    "# X_test_['q_3'] = pd.cut(X_test_['3'], 5)\n",
    "# X_test_['q_3'] = oe.transform(X_test_['q_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(y, 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test_results, meta_valid_results = kfold_train_predict(xgb, X_train_poly, y, X_test_poly, k=3, model_name='Meta_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test_results, meta_valid_results = kfold_train_predict(lasso, X_train_poly, y, X_test_poly, k=3, model_name='Meta_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = np.exp((np.log(lasso_test_results) + np.log(xgb_test_results) + np.log(lgb_test_results) + np.log(catb_test_results)) / 4 )\n",
    "results = np.exp(np.sum(np.log(np.column_stack(test_stack)) / 4, axis=1))\n",
    "#mean_squared_error(y, y3, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = meta_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above, we set `squared=False` to get the root mean squared error (RMSE) on the validation data.\n",
    "\n",
    "# Step 5: Submit to the competition\n",
    "\n",
    "We'll begin by using the trained model to generate predictions, which we'll save to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-16T22:54:17.068352Z",
     "iopub.status.idle": "2021-08-16T22:54:17.068911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'target': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
