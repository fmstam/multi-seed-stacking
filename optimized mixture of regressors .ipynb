{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the **[30 Days of ML competition](https://www.kaggle.com/c/30-days-of-ml/overview)**!  In this notebook, you'll learn how to make your first submission.\n",
    "\n",
    "Before getting started, make your own editable copy of this notebook by clicking on the **Copy and Edit** button.\n",
    "\n",
    "# Step 1: Import helpful libraries\n",
    "\n",
    "We begin by importing the libraries we'll need.  Some of them will be familiar from the **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course and the **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:09.725137Z",
     "iopub.status.busy": "2021-08-16T22:55:09.724708Z",
     "iopub.status.idle": "2021-08-16T22:55:09.73297Z",
     "shell.execute_reply": "2021-08-16T22:55:09.731277Z",
     "shell.execute_reply.started": "2021-08-16T22:55:09.725102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Familiar imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "\n",
    "\n",
    "# For ordinal encoding categorical variables, splitting data, pipeline, and so on\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, PowerTransformer, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# For training random forest model\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# base\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the data\n",
    "\n",
    "Next, we'll load the training and test data.  \n",
    "\n",
    "We set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:10.592447Z",
     "iopub.status.busy": "2021-08-16T22:55:10.591978Z",
     "iopub.status.idle": "2021-08-16T22:55:14.91458Z",
     "shell.execute_reply": "2021-08-16T22:55:14.912747Z",
     "shell.execute_reply.started": "2021-08-16T22:55:10.592407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.527335</td>\n",
       "      <td>0.230599</td>\n",
       "      <td>-0.118039</td>\n",
       "      <td>0.405965</td>\n",
       "      <td>0.497053</td>\n",
       "      <td>0.668060</td>\n",
       "      <td>1.058443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.460926</td>\n",
       "      <td>0.214003</td>\n",
       "      <td>-0.069309</td>\n",
       "      <td>0.310494</td>\n",
       "      <td>0.427903</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.887253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.490498</td>\n",
       "      <td>0.253346</td>\n",
       "      <td>-0.056104</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.502462</td>\n",
       "      <td>0.647512</td>\n",
       "      <td>1.034704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>0.219199</td>\n",
       "      <td>0.130676</td>\n",
       "      <td>0.329783</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.664451</td>\n",
       "      <td>1.039560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.491654</td>\n",
       "      <td>0.240074</td>\n",
       "      <td>0.255908</td>\n",
       "      <td>0.284188</td>\n",
       "      <td>0.390470</td>\n",
       "      <td>0.696599</td>\n",
       "      <td>1.055424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.510526</td>\n",
       "      <td>0.228232</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>0.354141</td>\n",
       "      <td>0.488865</td>\n",
       "      <td>0.669625</td>\n",
       "      <td>1.067649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.467476</td>\n",
       "      <td>0.210331</td>\n",
       "      <td>-0.224689</td>\n",
       "      <td>0.342873</td>\n",
       "      <td>0.429383</td>\n",
       "      <td>0.573383</td>\n",
       "      <td>1.111552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.537119</td>\n",
       "      <td>0.218140</td>\n",
       "      <td>0.203763</td>\n",
       "      <td>0.355825</td>\n",
       "      <td>0.504661</td>\n",
       "      <td>0.703441</td>\n",
       "      <td>1.032837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.498456</td>\n",
       "      <td>0.239920</td>\n",
       "      <td>-0.260275</td>\n",
       "      <td>0.332486</td>\n",
       "      <td>0.439151</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>1.040229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.474872</td>\n",
       "      <td>0.218007</td>\n",
       "      <td>0.117896</td>\n",
       "      <td>0.306874</td>\n",
       "      <td>0.434620</td>\n",
       "      <td>0.614333</td>\n",
       "      <td>0.982922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.474492</td>\n",
       "      <td>0.255949</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>0.276017</td>\n",
       "      <td>0.459975</td>\n",
       "      <td>0.691579</td>\n",
       "      <td>1.055960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.473216</td>\n",
       "      <td>0.222022</td>\n",
       "      <td>0.052608</td>\n",
       "      <td>0.308151</td>\n",
       "      <td>0.433812</td>\n",
       "      <td>0.642057</td>\n",
       "      <td>1.071444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.494561</td>\n",
       "      <td>0.247292</td>\n",
       "      <td>-0.074208</td>\n",
       "      <td>0.289074</td>\n",
       "      <td>0.422887</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>0.975035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.508273</td>\n",
       "      <td>0.222950</td>\n",
       "      <td>0.151050</td>\n",
       "      <td>0.300669</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.758447</td>\n",
       "      <td>0.905992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>8.241979</td>\n",
       "      <td>0.746555</td>\n",
       "      <td>0.140329</td>\n",
       "      <td>7.742071</td>\n",
       "      <td>8.191373</td>\n",
       "      <td>8.728634</td>\n",
       "      <td>10.411992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std       min       25%       50%       75%  \\\n",
       "cont0   300000.0  0.527335  0.230599 -0.118039  0.405965  0.497053  0.668060   \n",
       "cont1   300000.0  0.460926  0.214003 -0.069309  0.310494  0.427903  0.615113   \n",
       "cont2   300000.0  0.490498  0.253346 -0.056104  0.300604  0.502462  0.647512   \n",
       "cont3   300000.0  0.496689  0.219199  0.130676  0.329783  0.465026  0.664451   \n",
       "cont4   300000.0  0.491654  0.240074  0.255908  0.284188  0.390470  0.696599   \n",
       "cont5   300000.0  0.510526  0.228232  0.045915  0.354141  0.488865  0.669625   \n",
       "cont6   300000.0  0.467476  0.210331 -0.224689  0.342873  0.429383  0.573383   \n",
       "cont7   300000.0  0.537119  0.218140  0.203763  0.355825  0.504661  0.703441   \n",
       "cont8   300000.0  0.498456  0.239920 -0.260275  0.332486  0.439151  0.606056   \n",
       "cont9   300000.0  0.474872  0.218007  0.117896  0.306874  0.434620  0.614333   \n",
       "cont10  300000.0  0.474492  0.255949  0.048732  0.276017  0.459975  0.691579   \n",
       "cont11  300000.0  0.473216  0.222022  0.052608  0.308151  0.433812  0.642057   \n",
       "cont12  300000.0  0.494561  0.247292 -0.074208  0.289074  0.422887  0.714502   \n",
       "cont13  300000.0  0.508273  0.222950  0.151050  0.300669  0.472400  0.758447   \n",
       "target  300000.0  8.241979  0.746555  0.140329  7.742071  8.191373  8.728634   \n",
       "\n",
       "              max  \n",
       "cont0    1.058443  \n",
       "cont1    0.887253  \n",
       "cont2    1.034704  \n",
       "cont3    1.039560  \n",
       "cont4    1.055424  \n",
       "cont5    1.067649  \n",
       "cont6    1.111552  \n",
       "cont7    1.032837  \n",
       "cont8    1.040229  \n",
       "cont9    0.982922  \n",
       "cont10   1.055960  \n",
       "cont11   1.071444  \n",
       "cont12   0.975035  \n",
       "cont13   0.905992  \n",
       "target  10.411992  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "\n",
    "# Preview the data\n",
    "train.head()\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell separates the target (which we assign to `y`) from the training features (which we assign to `features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:14.916952Z",
     "iopub.status.busy": "2021-08-16T22:55:14.916515Z",
     "iopub.status.idle": "2021-08-16T22:55:14.984676Z",
     "shell.execute_reply": "2021-08-16T22:55:14.98316Z",
     "shell.execute_reply.started": "2021-08-16T22:55:14.916916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat0</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat1</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat2</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat3</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat4</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat5</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat6</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat7</th>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat8</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat9</th>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>0.20147</td>\n",
       "      <td>0.743068</td>\n",
       "      <td>0.742708</td>\n",
       "      <td>0.429551</td>\n",
       "      <td>1.05829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>-0.0148218</td>\n",
       "      <td>0.367411</td>\n",
       "      <td>0.310383</td>\n",
       "      <td>0.620998</td>\n",
       "      <td>0.367492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>0.669699</td>\n",
       "      <td>1.02161</td>\n",
       "      <td>-0.0126728</td>\n",
       "      <td>0.577942</td>\n",
       "      <td>-0.0523886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>0.136278</td>\n",
       "      <td>0.365798</td>\n",
       "      <td>0.576957</td>\n",
       "      <td>0.28061</td>\n",
       "      <td>0.232407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>0.610706</td>\n",
       "      <td>0.276853</td>\n",
       "      <td>0.285074</td>\n",
       "      <td>0.284667</td>\n",
       "      <td>0.287595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.533087</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.66898</td>\n",
       "      <td>0.686964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>0.160266</td>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.420667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.732948</td>\n",
       "      <td>0.648182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>0.38947</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.679618</td>\n",
       "      <td>0.684501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.956692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.34601</td>\n",
       "      <td>1.00077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.71461</td>\n",
       "      <td>0.776742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.54015</td>\n",
       "      <td>0.625849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>0.86985</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>0.763846</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>0.250823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id              1         2          3         4          6\n",
       "cat0            B         B          A         B          A\n",
       "cat1            B         B          A         B          A\n",
       "cat2            B         A          A         A          A\n",
       "cat3            C         A          C         C          C\n",
       "cat4            B         B          B         B          B\n",
       "cat5            B         D          D         D          D\n",
       "cat6            A         A          A         A          A\n",
       "cat7            E         F          D         E          E\n",
       "cat8            C         A          A         C          A\n",
       "cat9            N         O          F         K          N\n",
       "cont0     0.20147  0.743068   0.742708  0.429551    1.05829\n",
       "cont1  -0.0148218  0.367411   0.310383  0.620998   0.367492\n",
       "cont2    0.669699   1.02161 -0.0126728  0.577942 -0.0523886\n",
       "cont3    0.136278  0.365798   0.576957   0.28061   0.232407\n",
       "cont4    0.610706  0.276853   0.285074  0.284667   0.287595\n",
       "cont5    0.400361  0.533087   0.650609   0.66898   0.686964\n",
       "cont6    0.160266  0.558922   0.375348  0.239061   0.420667\n",
       "cont7    0.310921  0.516294   0.902567  0.732948   0.648182\n",
       "cont8     0.38947  0.594928   0.555205  0.679618   0.684501\n",
       "cont9    0.267559  0.341439   0.843531  0.574844   0.956692\n",
       "cont10   0.237281  0.906013   0.748809   0.34601    1.00077\n",
       "cont11   0.377873  0.921701   0.620126   0.71461   0.776742\n",
       "cont12   0.322401  0.261975   0.541474   0.54015   0.625849\n",
       "cont13    0.86985  0.465083   0.763846  0.280682   0.250823"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate target from features\n",
    "y = train['target']\n",
    "features = train.drop(['target'], axis=1)\n",
    "\n",
    "# Preview features\n",
    "features.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the data\n",
    "\n",
    "Next, we'll need to handle the categorical columns (`cat0`, `cat1`, ... `cat9`).  \n",
    "\n",
    "In the **[Categorical Variables lesson](https://www.kaggle.com/alexisbcook/categorical-variables)** in the Intermediate Machine Learning course, you learned several different ways to encode categorical variables in a dataset.  In this notebook, we'll use ordinal encoding and save our encoded features as new variables `X` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_poly_features(train, test, cols=None, concate=True, poly_degree=2):\n",
    "    \n",
    "    if cols is  None:\n",
    "        cols = train.columns\n",
    "     \n",
    "    columns = train[cols].columns\n",
    "    poly = PolynomialFeatures(poly_degree)\n",
    "    poly_train = pd.DataFrame(poly.fit_transform(train[cols]), index=train.index)\n",
    "    poly_test = pd.DataFrame(poly.transform(test[cols]), index=test.index)\n",
    "    \n",
    "    # stamp these columns\n",
    "    poly_train = poly_train.add_prefix('poly_')\n",
    "    poly_test = poly_test.add_prefix('poly_')\n",
    "    \n",
    "    if concate:\n",
    "        train = pd.concat([train, poly_train], axis=1)\n",
    "        test = pd.concat([test, poly_test], axis=1)\n",
    "        \n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:17.707975Z",
     "iopub.status.busy": "2021-08-16T22:55:17.7076Z",
     "iopub.status.idle": "2021-08-16T22:55:19.670568Z",
     "shell.execute_reply": "2021-08-16T22:55:19.669219Z",
     "shell.execute_reply.started": "2021-08-16T22:55:17.707941Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of categorical columns\n",
    "object_cols_long = [col for col in features.columns if 'cat' in col]\n",
    "cont_cols = [col for col in features.columns if 'con' in col]\n",
    "\n",
    "X = features.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "# cols = ['cont0', 'cont3', 'cont9']\n",
    "# add poly features\n",
    "# X, X_test = add_poly_features(X, X_test, cols)\n",
    "\n",
    "\n",
    "# encoding\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X[object_cols_long] = ordinal_encoder.fit_transform(X[object_cols_long])\n",
    "X_test[object_cols_long] = ordinal_encoder.transform(X_test[object_cols_long])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we break off a validation set from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:29.309502Z",
     "iopub.status.busy": "2021-08-16T22:55:29.309037Z",
     "iopub.status.idle": "2021-08-16T22:55:29.774149Z",
     "shell.execute_reply": "2021-08-16T22:55:29.772853Z",
     "shell.execute_reply.started": "2021-08-16T22:55:29.309468Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225000, 24)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.1: Predict using Generalized Stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "code_folding": [
     16,
     19,
     22,
     25
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# helpers and wrappers\n",
    "class ModelWrapper():\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 uses_eval_set=False,\n",
    "                 fit_params={}):\n",
    "        \n",
    "        self.model = model\n",
    "        self.name = model.__class__.__name__\n",
    "        \n",
    "        self.uses_eval_set = uses_val_set # if the model uses eval-set for early stopping\n",
    "        self.fit_params = fit_params # any extra params for the 'fit' function\n",
    "        \n",
    "#         self.valid_predictions = None # oof predictions on the valiation set\n",
    "#         self.test_predictions = None  # meta-features on the test set\n",
    "                \n",
    "    def train(self, X, y):\n",
    "        if self.use_eval_set:\n",
    "            self.model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], **(self.fit_kwargs))\n",
    "        else:\n",
    "            self.model.fit(X_train, y_train, **(self.fit_kwargs)) \n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "    def clone(self):\n",
    "        new_model = ModelWrapper(model=self.model,\n",
    "                                 uses_eval_set=self.use_eval_set,\n",
    "                                 fit_params=self.fit_params)\n",
    "        new_model.name = self.name\n",
    "        \n",
    "        return new_model\n",
    "        \n",
    "class Experiment():\n",
    "    def __init__(self,\n",
    "                 title='Experiment'\n",
    "                 n_folds=5,\n",
    "                 random_state=42):\n",
    "        \n",
    "        self.title = title\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "        self.time_stamp=datetime.now().isoformat(' ', 'seconds')\n",
    "    \n",
    "    def get_experiment(self):\n",
    "        return dict({\"title\": self.title,\n",
    "                    \"n_folds\": self.n_fold,\n",
    "                    \"random_state\": self.random_state,\n",
    "                    \"time_stamp\": self.time_stamp})\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.get_experiment())\n",
    "    \n",
    "        \n",
    "class LevelTrainer():\n",
    "    def __init__(self,\n",
    "                 level_num=1,\n",
    "                 \n",
    "                )\n",
    "\n",
    "def get_oof_predictions(model, X, y, X_test,\n",
    "                        n_folds=5, \n",
    "                        shuffle=True, \n",
    "                        random_state=42\n",
    "                        use_eval_set=False, \n",
    "                        **fit_kwargs):\n",
    "    \n",
    "    \"\"\" out of folds OOFs calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    kfolds = KFold(n_splits=k, \n",
    "                  shuffle=shuffle,\n",
    "                  random_state=random_state)\n",
    "    \n",
    "    test_predictions = 0\n",
    "    t_valid_predictions = np.zeros_like(np.array(y))\n",
    "    valid_mean_score = [] \n",
    "    \n",
    "    for fold, (train_index, valid_index) in enumerate(kfolds.split(X)):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        \n",
    "        # create a clone\n",
    "        model_ = clone(model)\n",
    "                \n",
    "        if use_eval_set:\n",
    "            model_.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], **fit_kwargs)\n",
    "        else:\n",
    "            model_.fit(X_train, y_train, **fit_kwargs)\n",
    "        \n",
    "        # validation score\n",
    "        valid_predications = model_.predict(X_valid)\n",
    "        score = mean_squared_error(valid_predications, y_valid, squared=False)\n",
    "        valid_mean_score.append(score)\n",
    "        \n",
    "        t_valid_predictions[valid_index] = valid_predications\n",
    "        \n",
    "        # test predictions\n",
    "        test_predictions += model_.predict(X_test) / k\n",
    "        \n",
    "        print('Fold:{} score:{:.4f}'.format(fold + 1, score))\n",
    "        \n",
    "    print('average score:{:.4f} ({:.4f})'.format(np.mean(valid_mean_score), np.std(valid_mean_score) ))\n",
    "    \n",
    "    return t_valid_predictions, test_predictions\n",
    "\n",
    "\n",
    "def store_oof_predictions(model_name,\n",
    "               valid_predictions,\n",
    "               test_predictions,\n",
    "               X_train,\n",
    "               X_test,\n",
    "               stacking_level, \n",
    "               n_folds, \n",
    "               random_state):    \n",
    "    \n",
    "    \"\"\"\n",
    "    Store oof predictions into files.\n",
    "    It is safe not to use defaults for this helper to make sure \n",
    "    we are storing the right experiement. \n",
    "    \"\"\"\n",
    "    assert model_name != ''\n",
    "    \n",
    "    if test_predictions is not None:\n",
    "        test_df = pd.DataFrame({'Id': X_test.index,\n",
    "                       model_name: test_predictions})\n",
    "        test_df.to_csv( 'level_{}/{}_{}_test.csv'.format(stacking_level, model_name, n_folds),\n",
    "                    index=False)\n",
    "        \n",
    "    if valid_predications is not None:\n",
    "        valid_df = pd.DataFrame({'Id': X_train.index,\n",
    "                           model_name: valid_predictions})\n",
    "        valid_df.to_csv('level_{}/{}_{}_valid.csv'.format(stacking_level, model_name, n_folds), \n",
    "                    index=False)\n",
    "    \n",
    "    \n",
    "def read_oof_predictions(pattern, \n",
    "                     models_names, \n",
    "                     index='id'):    \n",
    "    \"\"\"\n",
    "    Read files according the pattern in their name\n",
    "    it returns a dataframe where each column is the prediction of a model\n",
    "    \"\"\"\n",
    "    li = [] \n",
    "    for f in glob.glob(pattern):\n",
    "        file_name = f.split(os.sep)[1] # get file name only\n",
    "        if file_name.lower().startswith(tuple(s.lower() for s in models_names)): # get only required models\n",
    "            df = pd.read_csv(f, index_col=0)\n",
    "            li.append(df)\n",
    "    \n",
    "                                   \n",
    "    return pd.concat(li, axis=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamater ranges\n",
    "common ranges (to be added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters: these should go to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra-tree\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "# random forest\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "# xgboost\n",
    "# xgb_params = {'n_estimators': 10000,\n",
    "#               'learning_rate': 0.35,\n",
    "#               'subsample': 0.926,\n",
    "#               'colsample_bytree': 0.84,\n",
    "#               'max_depth': 2,\n",
    "#               'booster': 'gbtree', \n",
    "#               'reg_lambda': 35.1,\n",
    "#               'reg_alpha': 34.9,\n",
    "#               'random_state': 42,\n",
    "#               'n_jobs': -1}\n",
    "\n",
    "# Using optuna but still rough\n",
    "xgb_params = {'max_depth': 5,\n",
    "             'learning_rate': 0.021252439960137114,\n",
    "             'n_estimators': 13500,\n",
    "             'subsample': 0.62,\n",
    "             'booster': 'gbtree',\n",
    "             'colsample_bytree': 0.1,\n",
    "             'reg_lambda': 0.1584605320779582,\n",
    "             'reg_alpha': 15.715145781076245,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# catboost\n",
    "catb_params = {'iterations': 6800,\n",
    "              'learning_rate': 0.93,\n",
    "              'loss_function': \"RMSE\",\n",
    "              'random_state': 42,\n",
    "              'verbose': 0,\n",
    "              'thread_count': 4,\n",
    "              'depth': 1,\n",
    "              'l2_leaf_reg': 3.28,\n",
    "              'n_jobs': -1}\n",
    "\n",
    "SEED = 7770777\n",
    "params_lgb = {\"n_estimators\": 10000,   \n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"learning_rate\": 0.007899156646724397,\n",
    "            \"num_leaves\": 77,\n",
    "            \"max_depth\": 77,\n",
    "            \"feature_fraction\": 0.2256038826485174,\n",
    "            \"bagging_fraction\": 0.7705303688019942,\n",
    "            \"min_child_samples\": 290,\n",
    "            \"reg_alpha\": 9.562925363678952,\n",
    "            \"reg_lambda\": 9.355810045480153,\n",
    "            \"max_bin\": 772,\n",
    "            \"min_data_per_group\": 177,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"cat_smooth\": 96,\n",
    "            \"cat_l2\": 17,\n",
    "            \"verbosity\": -1,\n",
    "            \"bagging_seed\": SEED,\n",
    "            \"feature_fraction_seed\": SEED,\n",
    "            \"verbose_eval\":1000,\n",
    "            \"seed\": SEED,\n",
    "            \"n_jobs\":-1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external hyperparamaters\n",
    "\n",
    "### fit function hyperparamaters\n",
    "# some models require special paramaters like early stoping in xgboost and lgbm\n",
    "\n",
    "# xgboost\n",
    "xgb_fit_params = {'early_stopping_rounds': 200,\n",
    "                  'verbose': False}\n",
    "\n",
    "# lgbm\n",
    "lgb_fit_params = {'early_stopping_rounds': 200,\n",
    "                  'verbose': False}\n",
    "\n",
    "### application/implementation paramaters\n",
    "# These paramaters are implementation dependent \n",
    "\n",
    "# xgboost\n",
    "xgb_app_params = {'use_eval_set':True}\n",
    "\n",
    "# lgbm\n",
    "lgb_app_params = {'use_eval_set':True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.00005))\n",
    "\n",
    "# Elastic net\n",
    "e_net = make_pipeline(RobustScaler(), ElasticNet(alpha=0.00005, l1_ratio=.9))\n",
    "\n",
    "# KNeighborsRegressor\n",
    "knn = make_pipeline(RobustScaler(), KNeighborsRegressor())\n",
    "\n",
    "# extra-tree\n",
    "extree = ExtraTreesRegressor(**et_params)\n",
    "\n",
    "# random forest\n",
    "rfr = RandomForestRegressor(**rf_params)\n",
    "\n",
    "# xgboost\n",
    "xgb =  XGBRegressor(**xgb_params)\n",
    "\n",
    "#catboost\n",
    "catb = CatBoostRegressor(**catb_params)\n",
    "\n",
    "#lgbm\n",
    "lgb = LGBMRegressor(**params_lgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all settings in one dictionary, \n",
    "# we can store/load it then to a JSON file\n",
    "models = {'Lasso': {\"model\":lasso, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'ElasticNet': {\"model\": e_net, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'ExtraTreesRegressor': {\"model\": extree, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'RandomForestRegressor': {\"model\": rfr, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'XGBRegressor': {\"model\": xgb, \"fit_kwargs\":xgb_fit_params, \"app_params\": xgb_fit_params},\n",
    "          'CatBoostRegressor': {\"model\": catb, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'LGBMRegressor': {\"model\": lgb, \"fit_kwargs\":lgb_fit_params, \"app_params\": lgb_app_params}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking with two levels:\n",
    "we need two things:\n",
    "\n",
    "oof predictions and test results.\n",
    "- train level 1 models and collect their oof predictions \n",
    "- use oof predictions in another model and predict the final target.\n",
    "\n",
    "- there are some variations to this simple procedure: see \n",
    " - https://mlwave.com/kaggle-ensembling-guide/\n",
    " - https://www.kaggle.com/getting-started/18153#post103381\n",
    " \n",
    "- one approach would be to:\n",
    "    - train N models in the first level and get their oof predictions\n",
    "    - train a model on the whole train set and get it's predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['RandomForestRegressor', \n",
    "# 'ExtraTreesRegressor',\n",
    "# 'XGBRegressor',\n",
    "# 'CatBoostRegressor'\n",
    "# ]\n",
    "\n",
    "\n",
    "experiment_settings = { 'level_1_models': ['all'],\n",
    "                        'meta_model': 'XGBRegressor',\n",
    "                        'n_folds_list': [5],\n",
    "                        'random_states' : [42],\n",
    "                        'verbose' : True      \n",
    "                      }\n",
    "\n",
    "# if level_1_models is set to 'all' use the models\n",
    "if experiment_settings['level_1_models'][0].lower() == 'all':\n",
    "    level_1_models_names = models.keys()\n",
    "else: \n",
    "    level_1_models_names = experiment_settings['level_1_models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Lasso\n",
      "Calculating oof predictions\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'use_eval_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-fd0d4390d0e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                          \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                          \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                                          \u001b[0muse_eval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_eval_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                                                          fit_kwargs=fit_kwargs)\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Storing oof predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'use_eval_set' is not defined"
     ]
    }
   ],
   "source": [
    "# main procedure\n",
    "for k, state in zip(experiment_settings['n_folds_list'], \n",
    "                          experiment_settings['random_states']):\n",
    "    \n",
    "    for model_name in level_1_models_names:\n",
    "        \n",
    "        # get paramaters for \n",
    "        model = models[model_name]\n",
    "        fit_kwargs = models[model_name]['fit_kwargs']\n",
    "        app_params = models[model_name]['app_params'] \n",
    "        \n",
    "        print('-'*30)\n",
    "        print (model_name)\n",
    "        print('Calculating oof predictions')\n",
    "        \n",
    "        # get oof predictions \n",
    "        if fit_kwargs is not None:\n",
    "            oof_validations, oof_tests = get_oof_predictions(model,X, y, X_test,\n",
    "                                                             k, \n",
    "                                                             random_state=state,\n",
    "                                                             use_eval_set=app_params['use_eval_set'],\n",
    "                                                             fit_kwargs=fit_kwargs)\n",
    " \n",
    "        print('Storing oof predictions')\n",
    "        # store them\n",
    "        store_oof_predictions(name, \n",
    "                              oof_validations, \n",
    "                              oof_tests, \n",
    "                              X, X_test, \n",
    "                              stacking_level=1, \n",
    "                              n_folds=k, random_state=state)\n",
    "        print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach I am going to run k-folds using each model and average the rest results among folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7434\n",
      "Fold:2 score:0.7340\n",
      "Fold:3 score:0.7360\n",
      "Fold:4 score:0.7370\n",
      "Fold:5 score:0.7451\n",
      "Fold:6 score:0.7421\n",
      "Fold:7 score:0.7342\n",
      "Fold:8 score:0.7404\n",
      "Fold:9 score:0.7352\n",
      "Fold:10 score:0.7421\n",
      "Fold:11 score:0.7447\n",
      "Fold:12 score:0.7363\n",
      "average score:0.7392 (0.0040)\n"
     ]
    }
   ],
   "source": [
    "lasso_test_results, lasso_valid_results = calc_oof_predictions(lasso, X, y, X_test, model_name='lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7434\n",
      "Fold:2 score:0.7340\n",
      "Fold:3 score:0.7360\n",
      "Fold:4 score:0.7370\n",
      "Fold:5 score:0.7451\n",
      "Fold:6 score:0.7421\n",
      "Fold:7 score:0.7342\n",
      "Fold:8 score:0.7405\n",
      "Fold:9 score:0.7352\n",
      "Fold:10 score:0.7421\n",
      "Fold:11 score:0.7447\n",
      "Fold:12 score:0.7363\n",
      "average score:0.7392 (0.0040)\n"
     ]
    }
   ],
   "source": [
    "enet_test_results, enet_valid_results = calc_oof_predictions(e_net, X, y, X_test, model_name='Enet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7191\n",
      "Fold:2 score:0.7138\n",
      "Fold:3 score:0.7136\n",
      "Fold:4 score:0.7155\n",
      "Fold:5 score:0.7210\n",
      "Fold:6 score:0.7201\n",
      "Fold:7 score:0.7142\n",
      "Fold:8 score:0.7187\n",
      "Fold:9 score:0.7140\n",
      "Fold:10 score:0.7200\n",
      "Fold:11 score:0.7200\n",
      "Fold:12 score:0.7120\n",
      "average score:0.7168 (0.0031)\n"
     ]
    }
   ],
   "source": [
    "xgb_test_results, xgb_valid_results = calc_oof_predictions(xgb, X, y, X_test, use_eval_set=True,\n",
    "                   early_stopping_rounds=200,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7199\n",
      "Fold:2 score:0.7138\n",
      "Fold:3 score:0.7141\n",
      "Fold:4 score:0.7164\n",
      "Fold:5 score:0.7213\n",
      "Fold:6 score:0.7203\n",
      "Fold:7 score:0.7138\n",
      "Fold:8 score:0.7192\n",
      "Fold:9 score:0.7142\n",
      "Fold:10 score:0.7205\n",
      "Fold:11 score:0.7211\n",
      "Fold:12 score:0.7131\n",
      "average score:0.7173 (0.0032)\n"
     ]
    }
   ],
   "source": [
    "lgb_test_results, lgb_valid_results = calc_oof_predictions(lgb, X, y, X_test, use_eval_set=True,\n",
    "                   early_stopping_rounds=200,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7209\n",
      "Fold:2 score:0.7145\n",
      "Fold:3 score:0.7149\n",
      "Fold:4 score:0.7175\n",
      "Fold:5 score:0.7224\n",
      "Fold:6 score:0.7209\n",
      "Fold:7 score:0.7149\n",
      "Fold:8 score:0.7203\n",
      "Fold:9 score:0.7146\n",
      "Fold:10 score:0.7215\n",
      "Fold:11 score:0.7219\n",
      "Fold:12 score:0.7138\n",
      "average score:0.7182 (0.0033)\n"
     ]
    }
   ],
   "source": [
    "catb_test_results, catb_valid_results = calc_oof_predictions(catb, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7396\n",
      "Fold:2 score:0.7313\n",
      "Fold:3 score:0.7334\n",
      "Fold:4 score:0.7348\n",
      "Fold:5 score:0.7421\n",
      "Fold:6 score:0.7399\n",
      "Fold:7 score:0.7316\n",
      "Fold:8 score:0.7382\n",
      "Fold:9 score:0.7327\n",
      "Fold:10 score:0.7397\n",
      "Fold:11 score:0.7418\n",
      "Fold:12 score:0.7336\n",
      "average score:0.7366 (0.0039)\n"
     ]
    }
   ],
   "source": [
    "extree_test_results, extree_valid_results = calc_oof_predictions(extree, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7401\n",
      "Fold:2 score:0.7317\n",
      "Fold:3 score:0.7336\n",
      "Fold:4 score:0.7348\n",
      "Fold:5 score:0.7420\n",
      "Fold:6 score:0.7396\n",
      "Fold:7 score:0.7318\n",
      "Fold:8 score:0.7381\n",
      "Fold:9 score:0.7328\n",
      "Fold:10 score:0.7396\n",
      "Fold:11 score:0.7416\n",
      "Fold:12 score:0.7337\n",
      "average score:0.7366 (0.0038)\n"
     ]
    }
   ],
   "source": [
    "rfr_test_results, rfr_valid_results = calc_oof_predictions(rfr, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet_12_valid.csv\n",
      "Lasso_12_valid.csv\n",
      "CatBoostRegressor_12_valid.csv\n",
      "RandomForestRegressor_12_valid.csv\n",
      "XGBRegressor_12_valid.csv\n",
      "ExtraTreesRegressor_12_valid.csv\n",
      "LGBMRegressor_12_valid.csv\n",
      "4\n",
      "ExtraTreesRegressor_12_test.csv\n",
      "CatBoostRegressor_12_test.csv\n",
      "LGBMRegressor_12_test.csv\n",
      "ElasticNet_12_test.csv\n",
      "XGBRegressor_12_test.csv\n",
      "Lasso_12_test.csv\n",
      "RandomForestRegressor_12_test.csv\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature</th>\n",
       "      <th>feature</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.457421</td>\n",
       "      <td>8.255680</td>\n",
       "      <td>8.419353</td>\n",
       "      <td>8.244644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.361938</td>\n",
       "      <td>8.315244</td>\n",
       "      <td>8.432220</td>\n",
       "      <td>8.293434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.222198</td>\n",
       "      <td>8.140362</td>\n",
       "      <td>8.180540</td>\n",
       "      <td>8.156236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.392812</td>\n",
       "      <td>8.279955</td>\n",
       "      <td>8.401962</td>\n",
       "      <td>8.284501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.278599</td>\n",
       "      <td>8.187986</td>\n",
       "      <td>8.133272</td>\n",
       "      <td>8.189441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature   feature   feature   feature\n",
       "Id                                        \n",
       "1   8.457421  8.255680  8.419353  8.244644\n",
       "2   8.361938  8.315244  8.432220  8.293434\n",
       "3   8.222198  8.140362  8.180540  8.156236\n",
       "4   8.392812  8.279955  8.401962  8.284501\n",
       "6   8.278599  8.187986  8.133272  8.189441"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                         \n",
    "# required results                            \n",
    "fold_id = 12\n",
    "folder ='level_1'\n",
    "                            \n",
    "level_1_models = ['RandomForestRegressor', \n",
    "                  'ExtraTreesRegressor',\n",
    "                  'XGBRegressor',\n",
    "                  'CatBoostRegressor'\n",
    "                  ]\n",
    "\n",
    "meta_regressor = 'LGBMRegressor'\n",
    "\n",
    "\n",
    "\n",
    "# new features \n",
    "X_train_ = read_results_set(pattern=f\"{folder}{os.sep}*{fold_id}_valid.csv\",\n",
    "                           models_names=level_1_models)\n",
    "X_test_ = read_results_set(pattern=f\"{folder}{os.sep}*{fold_id}_test.csv\",\n",
    "                          models_names=level_1_models)\n",
    "\n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_.columns = [str(i) for i in range(len(X_train_.columns))]\n",
    "X_test_.columns = [str(i) for i in range(len(X_train_.columns))]\n",
    "#X_train_, X_test_ = add_poly_features(X_train_, X_test_, concate=True, poly_degree=2)\n",
    "#X_train_.drop(['poly_0', 'poly_1' ,'poly_2','poly_3', 'poly_4'], inplace =True, axis=1)\n",
    "#X_test_.drop(['poly_0', 'poly_1' ,'poly_2','poly_3', 'poly_4'], inplace =True, axis=1)\n",
    "# X_train_['q_3'] = pd.qcut(X_train_['3'], 35)\n",
    "# y_ = pd.cut(y, 5)\n",
    "# oe = LabelEncoder()\n",
    "# X_train_['q_3'] = oe.fit(y_).transform(X_train_['3'])\n",
    "# X_test_['q_3'] = pd.cut(X_test_['3'], 5)\n",
    "# X_test_['q_3'] = oe.transform(X_test_['q_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>,\n",
       "        <AxesSubplot:title={'center':'1'}>],\n",
       "       [<AxesSubplot:title={'center':'2'}>,\n",
       "        <AxesSubplot:title={'center':'3'}>]], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(y, 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-1ae3c9cfcca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_test_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_valid_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Meta_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-101-56b9dc38b59f>\u001b[0m in \u001b[0;36mget_oof_predictions\u001b[0;34m(model, X, y, X_test, model_name, stacking_level, k, shuffle, use_eval_set, multi, store, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# validation score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[1;32m    540\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     return _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    209\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meta_test_results, meta_valid_results = get_oof_predictions(xgb, X_train, y, X_test, k=5, model_name='Meta_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7161\n",
      "Fold:2 score:0.7160\n",
      "Fold:3 score:0.7180\n",
      "Fold:4 score:0.7177\n",
      "Fold:5 score:0.7158\n",
      "average score:0.7167 (0.0010)\n"
     ]
    }
   ],
   "source": [
    "meta_valid_results, meta_test_results = get_oof_predictions(lasso, X_train_, y, X_test_, k=5, model_name='Meta_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = np.exp((np.log(lasso_test_results) + np.log(xgb_test_results) + np.log(lgb_test_results) + np.log(catb_test_results)) / 4 )\n",
    "results = np.exp(np.sum(np.log(np.column_stack(test_stack)) / 4, axis=1))\n",
    "#mean_squared_error(y, y3, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = meta_valid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above, we set `squared=False` to get the root mean squared error (RMSE) on the validation data.\n",
    "\n",
    "# Step 5: Submit to the competition\n",
    "\n",
    "We'll begin by using the trained model to generate predictions, which we'll save to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-16T22:54:17.068352Z",
     "iopub.status.idle": "2021-08-16T22:54:17.068911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'target': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.069916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8.343784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>8.361576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>8.417953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>8.155354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>8.284881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>8.462473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>7.935788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>8.136220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>8.309392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    target\n",
       "0   0  8.069916\n",
       "1   5  8.343784\n",
       "2  15  8.361576\n",
       "3  16  8.417953\n",
       "4  17  8.155354\n",
       "5  19  8.284881\n",
       "6  20  8.462473\n",
       "7  21  7.935788\n",
       "8  23  8.136220\n",
       "9  29  8.309392"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
