{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the **[30 Days of ML competition](https://www.kaggle.com/c/30-days-of-ml/overview)**!  In this notebook, you'll learn how to make your first submission.\n",
    "\n",
    "Before getting started, make your own editable copy of this notebook by clicking on the **Copy and Edit** button.\n",
    "\n",
    "# Step 1: Import helpful libraries\n",
    "\n",
    "We begin by importing the libraries we'll need.  Some of them will be familiar from the **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course and the **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:09.725137Z",
     "iopub.status.busy": "2021-08-16T22:55:09.724708Z",
     "iopub.status.idle": "2021-08-16T22:55:09.73297Z",
     "shell.execute_reply": "2021-08-16T22:55:09.731277Z",
     "shell.execute_reply.started": "2021-08-16T22:55:09.725102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Familiar imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "\n",
    "\n",
    "# For ordinal encoding categorical variables, splitting data, pipeline, and so on\n",
    "from sklearn.preprocessing import OrdinalEncoder, PowerTransformer, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# For training random forest model\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# base\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the data\n",
    "\n",
    "Next, we'll load the training and test data.  \n",
    "\n",
    "We set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:10.592447Z",
     "iopub.status.busy": "2021-08-16T22:55:10.591978Z",
     "iopub.status.idle": "2021-08-16T22:55:14.91458Z",
     "shell.execute_reply": "2021-08-16T22:55:14.912747Z",
     "shell.execute_reply.started": "2021-08-16T22:55:10.592407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont0</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.527335</td>\n",
       "      <td>0.460926</td>\n",
       "      <td>0.490498</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>0.491654</td>\n",
       "      <td>0.510526</td>\n",
       "      <td>0.467476</td>\n",
       "      <td>0.537119</td>\n",
       "      <td>0.498456</td>\n",
       "      <td>0.474872</td>\n",
       "      <td>0.474492</td>\n",
       "      <td>0.473216</td>\n",
       "      <td>0.494561</td>\n",
       "      <td>0.508273</td>\n",
       "      <td>8.241979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.230599</td>\n",
       "      <td>0.214003</td>\n",
       "      <td>0.253346</td>\n",
       "      <td>0.219199</td>\n",
       "      <td>0.240074</td>\n",
       "      <td>0.228232</td>\n",
       "      <td>0.210331</td>\n",
       "      <td>0.218140</td>\n",
       "      <td>0.239920</td>\n",
       "      <td>0.218007</td>\n",
       "      <td>0.255949</td>\n",
       "      <td>0.222022</td>\n",
       "      <td>0.247292</td>\n",
       "      <td>0.222950</td>\n",
       "      <td>0.746555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.118039</td>\n",
       "      <td>-0.069309</td>\n",
       "      <td>-0.056104</td>\n",
       "      <td>0.130676</td>\n",
       "      <td>0.255908</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>-0.224689</td>\n",
       "      <td>0.203763</td>\n",
       "      <td>-0.260275</td>\n",
       "      <td>0.117896</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>0.052608</td>\n",
       "      <td>-0.074208</td>\n",
       "      <td>0.151050</td>\n",
       "      <td>0.140329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.405965</td>\n",
       "      <td>0.310494</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.329783</td>\n",
       "      <td>0.284188</td>\n",
       "      <td>0.354141</td>\n",
       "      <td>0.342873</td>\n",
       "      <td>0.355825</td>\n",
       "      <td>0.332486</td>\n",
       "      <td>0.306874</td>\n",
       "      <td>0.276017</td>\n",
       "      <td>0.308151</td>\n",
       "      <td>0.289074</td>\n",
       "      <td>0.300669</td>\n",
       "      <td>7.742071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.497053</td>\n",
       "      <td>0.427903</td>\n",
       "      <td>0.502462</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.390470</td>\n",
       "      <td>0.488865</td>\n",
       "      <td>0.429383</td>\n",
       "      <td>0.504661</td>\n",
       "      <td>0.439151</td>\n",
       "      <td>0.434620</td>\n",
       "      <td>0.459975</td>\n",
       "      <td>0.433812</td>\n",
       "      <td>0.422887</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>8.191373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.668060</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.647512</td>\n",
       "      <td>0.664451</td>\n",
       "      <td>0.696599</td>\n",
       "      <td>0.669625</td>\n",
       "      <td>0.573383</td>\n",
       "      <td>0.703441</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>0.614333</td>\n",
       "      <td>0.691579</td>\n",
       "      <td>0.642057</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>0.758447</td>\n",
       "      <td>8.728634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.058443</td>\n",
       "      <td>0.887253</td>\n",
       "      <td>1.034704</td>\n",
       "      <td>1.039560</td>\n",
       "      <td>1.055424</td>\n",
       "      <td>1.067649</td>\n",
       "      <td>1.111552</td>\n",
       "      <td>1.032837</td>\n",
       "      <td>1.040229</td>\n",
       "      <td>0.982922</td>\n",
       "      <td>1.055960</td>\n",
       "      <td>1.071444</td>\n",
       "      <td>0.975035</td>\n",
       "      <td>0.905992</td>\n",
       "      <td>10.411992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cont0          cont1          cont2          cont3  \\\n",
       "count  300000.000000  300000.000000  300000.000000  300000.000000   \n",
       "mean        0.527335       0.460926       0.490498       0.496689   \n",
       "std         0.230599       0.214003       0.253346       0.219199   \n",
       "min        -0.118039      -0.069309      -0.056104       0.130676   \n",
       "25%         0.405965       0.310494       0.300604       0.329783   \n",
       "50%         0.497053       0.427903       0.502462       0.465026   \n",
       "75%         0.668060       0.615113       0.647512       0.664451   \n",
       "max         1.058443       0.887253       1.034704       1.039560   \n",
       "\n",
       "               cont4          cont5          cont6          cont7  \\\n",
       "count  300000.000000  300000.000000  300000.000000  300000.000000   \n",
       "mean        0.491654       0.510526       0.467476       0.537119   \n",
       "std         0.240074       0.228232       0.210331       0.218140   \n",
       "min         0.255908       0.045915      -0.224689       0.203763   \n",
       "25%         0.284188       0.354141       0.342873       0.355825   \n",
       "50%         0.390470       0.488865       0.429383       0.504661   \n",
       "75%         0.696599       0.669625       0.573383       0.703441   \n",
       "max         1.055424       1.067649       1.111552       1.032837   \n",
       "\n",
       "               cont8          cont9         cont10         cont11  \\\n",
       "count  300000.000000  300000.000000  300000.000000  300000.000000   \n",
       "mean        0.498456       0.474872       0.474492       0.473216   \n",
       "std         0.239920       0.218007       0.255949       0.222022   \n",
       "min        -0.260275       0.117896       0.048732       0.052608   \n",
       "25%         0.332486       0.306874       0.276017       0.308151   \n",
       "50%         0.439151       0.434620       0.459975       0.433812   \n",
       "75%         0.606056       0.614333       0.691579       0.642057   \n",
       "max         1.040229       0.982922       1.055960       1.071444   \n",
       "\n",
       "              cont12         cont13         target  \n",
       "count  300000.000000  300000.000000  300000.000000  \n",
       "mean        0.494561       0.508273       8.241979  \n",
       "std         0.247292       0.222950       0.746555  \n",
       "min        -0.074208       0.151050       0.140329  \n",
       "25%         0.289074       0.300669       7.742071  \n",
       "50%         0.422887       0.472400       8.191373  \n",
       "75%         0.714502       0.758447       8.728634  \n",
       "max         0.975035       0.905992      10.411992  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "\n",
    "# Preview the data\n",
    "train.head()\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell separates the target (which we assign to `y`) from the training features (which we assign to `features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:14.916952Z",
     "iopub.status.busy": "2021-08-16T22:55:14.916515Z",
     "iopub.status.idle": "2021-08-16T22:55:14.984676Z",
     "shell.execute_reply": "2021-08-16T22:55:14.98316Z",
     "shell.execute_reply.started": "2021-08-16T22:55:14.916916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cont0</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>0.201470</td>\n",
       "      <td>-0.014822</td>\n",
       "      <td>0.669699</td>\n",
       "      <td>0.136278</td>\n",
       "      <td>0.610706</td>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.160266</td>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.389470</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.869850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>0.743068</td>\n",
       "      <td>0.367411</td>\n",
       "      <td>1.021605</td>\n",
       "      <td>0.365798</td>\n",
       "      <td>0.276853</td>\n",
       "      <td>0.533087</td>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.465083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0.742708</td>\n",
       "      <td>0.310383</td>\n",
       "      <td>-0.012673</td>\n",
       "      <td>0.576957</td>\n",
       "      <td>0.285074</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.763846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>0.429551</td>\n",
       "      <td>0.620998</td>\n",
       "      <td>0.577942</td>\n",
       "      <td>0.280610</td>\n",
       "      <td>0.284667</td>\n",
       "      <td>0.668980</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.732948</td>\n",
       "      <td>0.679618</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.714610</td>\n",
       "      <td>0.540150</td>\n",
       "      <td>0.280682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>1.058291</td>\n",
       "      <td>0.367492</td>\n",
       "      <td>-0.052389</td>\n",
       "      <td>0.232407</td>\n",
       "      <td>0.287595</td>\n",
       "      <td>0.686964</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>0.648182</td>\n",
       "      <td>0.684501</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>1.000773</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>0.625849</td>\n",
       "      <td>0.250823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9     cont0     cont1  \\\n",
       "id                                                                         \n",
       "1     B    B    B    C    B    B    A    E    C    N  0.201470 -0.014822   \n",
       "2     B    B    A    A    B    D    A    F    A    O  0.743068  0.367411   \n",
       "3     A    A    A    C    B    D    A    D    A    F  0.742708  0.310383   \n",
       "4     B    B    A    C    B    D    A    E    C    K  0.429551  0.620998   \n",
       "6     A    A    A    C    B    D    A    E    A    N  1.058291  0.367492   \n",
       "\n",
       "       cont2     cont3     cont4     cont5     cont6     cont7     cont8  \\\n",
       "id                                                                         \n",
       "1   0.669699  0.136278  0.610706  0.400361  0.160266  0.310921  0.389470   \n",
       "2   1.021605  0.365798  0.276853  0.533087  0.558922  0.516294  0.594928   \n",
       "3  -0.012673  0.576957  0.285074  0.650609  0.375348  0.902567  0.555205   \n",
       "4   0.577942  0.280610  0.284667  0.668980  0.239061  0.732948  0.679618   \n",
       "6  -0.052389  0.232407  0.287595  0.686964  0.420667  0.648182  0.684501   \n",
       "\n",
       "       cont9    cont10    cont11    cont12    cont13  \n",
       "id                                                    \n",
       "1   0.267559  0.237281  0.377873  0.322401  0.869850  \n",
       "2   0.341439  0.906013  0.921701  0.261975  0.465083  \n",
       "3   0.843531  0.748809  0.620126  0.541474  0.763846  \n",
       "4   0.574844  0.346010  0.714610  0.540150  0.280682  \n",
       "6   0.956692  1.000773  0.776742  0.625849  0.250823  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate target from features\n",
    "y = train['target']\n",
    "features = train.drop(['target'], axis=1)\n",
    "\n",
    "# Preview features\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the data\n",
    "\n",
    "Next, we'll need to handle the categorical columns (`cat0`, `cat1`, ... `cat9`).  \n",
    "\n",
    "In the **[Categorical Variables lesson](https://www.kaggle.com/alexisbcook/categorical-variables)** in the Intermediate Machine Learning course, you learned several different ways to encode categorical variables in a dataset.  In this notebook, we'll use ordinal encoding and save our encoded features as new variables `X` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_features(df, cols):\n",
    "    columns = df[cols].columns\n",
    "    for c in columns:\n",
    "        df[c + '_sq'] = df[c].pow(2)\n",
    "    return df\n",
    "        \n",
    "# List of categorical columns\n",
    "object_cols_long = [col for col in features.columns if 'cat' in col]\n",
    "cont_cols = [col for col in features.columns if 'con' in col]\n",
    "\n",
    "# new_features = squared_features(features, cont_cols)\n",
    "# new_features.sample(10)\n",
    "\n",
    "\n",
    "\n",
    "new_features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 1 to 499999\n",
      "Data columns (total 24 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   cat0    300000 non-null  object \n",
      " 1   cat1    300000 non-null  object \n",
      " 2   cat2    300000 non-null  object \n",
      " 3   cat3    300000 non-null  object \n",
      " 4   cat4    300000 non-null  object \n",
      " 5   cat5    300000 non-null  object \n",
      " 6   cat6    300000 non-null  object \n",
      " 7   cat7    300000 non-null  object \n",
      " 8   cat8    300000 non-null  object \n",
      " 9   cat9    300000 non-null  object \n",
      " 10  cont0   300000 non-null  float64\n",
      " 11  cont1   300000 non-null  float64\n",
      " 12  cont2   300000 non-null  float64\n",
      " 13  cont3   300000 non-null  float64\n",
      " 14  cont4   300000 non-null  float64\n",
      " 15  cont5   300000 non-null  float64\n",
      " 16  cont6   300000 non-null  float64\n",
      " 17  cont7   300000 non-null  float64\n",
      " 18  cont8   300000 non-null  float64\n",
      " 19  cont9   300000 non-null  float64\n",
      " 20  cont10  300000 non-null  float64\n",
      " 21  cont11  300000 non-null  float64\n",
      " 22  cont12  300000 non-null  float64\n",
      " 23  cont13  300000 non-null  float64\n",
      "dtypes: float64(14), object(10)\n",
      "memory usage: 57.2+ MB\n"
     ]
    }
   ],
   "source": [
    "new_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:17.707975Z",
     "iopub.status.busy": "2021-08-16T22:55:17.7076Z",
     "iopub.status.idle": "2021-08-16T22:55:19.670568Z",
     "shell.execute_reply": "2021-08-16T22:55:19.669219Z",
     "shell.execute_reply.started": "2021-08-16T22:55:17.707941Z"
    }
   },
   "outputs": [],
   "source": [
    "# ordinal-encode categorical columns\n",
    "X = new_features.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "\n",
    "# skewness\n",
    "# lam = 0.70\n",
    "# for col in ('cont0', 'cont1', 'cont3', 'cont4'):\n",
    "#     X[col] = boxcox1p(X[col], lam)\n",
    "#     X_test[col] = boxcox1p(X_test[col], lam)\n",
    "\n",
    "\n",
    "# encoding\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X[object_cols_long] = ordinal_encoder.fit_transform(features[object_cols_long])\n",
    "X_test[object_cols_long] = ordinal_encoder.transform(test[object_cols_long])\n",
    "\n",
    "pr_transformer = PowerTransformer(standardize=True)\n",
    "cols = ['cont0', 'cont1', 'cont3', 'cont4']\n",
    "cols = cont_cols\n",
    "X[cols] = pr_transformer.fit_transform(X[cols].values)\n",
    "X_test[cols] = pr_transformer.transform(X_test[cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:25.668319Z",
     "iopub.status.busy": "2021-08-16T22:55:25.667774Z",
     "iopub.status.idle": "2021-08-16T22:55:27.018155Z",
     "shell.execute_reply": "2021-08-16T22:55:27.016603Z",
     "shell.execute_reply.started": "2021-08-16T22:55:25.668284Z"
    }
   },
   "outputs": [],
   "source": [
    "# _, ax = plt.subplots(figsize=(18, 12))\n",
    "# sns.heatmap(new_features.corr(), annot=True, square=True,linewidths=.5, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we break off a validation set from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:29.309502Z",
     "iopub.status.busy": "2021-08-16T22:55:29.309037Z",
     "iopub.status.idle": "2021-08-16T22:55:29.774149Z",
     "shell.execute_reply": "2021-08-16T22:55:29.772853Z",
     "shell.execute_reply.started": "2021-08-16T22:55:29.309468Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>412957</th>\n",
       "      <th>282449</th>\n",
       "      <th>164867</th>\n",
       "      <th>541</th>\n",
       "      <th>80790</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat3</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat5</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat7</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat8</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat9</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>2.094562</td>\n",
       "      <td>0.143735</td>\n",
       "      <td>-0.985471</td>\n",
       "      <td>-0.424895</td>\n",
       "      <td>0.626901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>-0.137775</td>\n",
       "      <td>0.150796</td>\n",
       "      <td>-0.767856</td>\n",
       "      <td>-2.401788</td>\n",
       "      <td>0.479774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>-0.499913</td>\n",
       "      <td>1.644785</td>\n",
       "      <td>-2.237025</td>\n",
       "      <td>0.563226</td>\n",
       "      <td>-1.088116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>0.308463</td>\n",
       "      <td>-0.362960</td>\n",
       "      <td>-1.838414</td>\n",
       "      <td>-1.241144</td>\n",
       "      <td>0.781711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>-0.966433</td>\n",
       "      <td>1.574703</td>\n",
       "      <td>0.505668</td>\n",
       "      <td>1.277541</td>\n",
       "      <td>1.304526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>1.155671</td>\n",
       "      <td>-0.495239</td>\n",
       "      <td>1.536780</td>\n",
       "      <td>-1.144258</td>\n",
       "      <td>-0.384343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>-0.319150</td>\n",
       "      <td>-0.314127</td>\n",
       "      <td>1.073306</td>\n",
       "      <td>-0.889242</td>\n",
       "      <td>-0.547768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>0.324519</td>\n",
       "      <td>-1.505026</td>\n",
       "      <td>-0.588210</td>\n",
       "      <td>-1.560941</td>\n",
       "      <td>0.153452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>-0.139562</td>\n",
       "      <td>-1.022767</td>\n",
       "      <td>-0.477780</td>\n",
       "      <td>0.283176</td>\n",
       "      <td>1.991112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>1.432335</td>\n",
       "      <td>-0.838888</td>\n",
       "      <td>0.669739</td>\n",
       "      <td>-0.674801</td>\n",
       "      <td>-0.086206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>0.661177</td>\n",
       "      <td>1.082046</td>\n",
       "      <td>0.994891</td>\n",
       "      <td>-1.533345</td>\n",
       "      <td>1.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>0.707830</td>\n",
       "      <td>-1.819822</td>\n",
       "      <td>0.508727</td>\n",
       "      <td>-0.128344</td>\n",
       "      <td>0.851442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>1.437093</td>\n",
       "      <td>-1.103376</td>\n",
       "      <td>-0.424387</td>\n",
       "      <td>-1.314553</td>\n",
       "      <td>1.663873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>1.245853</td>\n",
       "      <td>1.484426</td>\n",
       "      <td>0.197321</td>\n",
       "      <td>-1.219126</td>\n",
       "      <td>-0.079826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id        412957    282449     164867    541       80790 \n",
       "cat0    0.000000  0.000000   0.000000  0.000000  1.000000\n",
       "cat1    0.000000  0.000000   0.000000  1.000000  1.000000\n",
       "cat2    0.000000  0.000000   0.000000  0.000000  0.000000\n",
       "cat3    2.000000  2.000000   0.000000  2.000000  2.000000\n",
       "cat4    1.000000  1.000000   1.000000  1.000000  1.000000\n",
       "cat5    2.000000  1.000000   1.000000  1.000000  3.000000\n",
       "cat6    0.000000  0.000000   0.000000  0.000000  0.000000\n",
       "cat7    3.000000  4.000000   4.000000  4.000000  4.000000\n",
       "cat8    6.000000  4.000000   5.000000  4.000000  0.000000\n",
       "cat9    7.000000  8.000000  14.000000  6.000000  8.000000\n",
       "cont0   2.094562  0.143735  -0.985471 -0.424895  0.626901\n",
       "cont1  -0.137775  0.150796  -0.767856 -2.401788  0.479774\n",
       "cont2  -0.499913  1.644785  -2.237025  0.563226 -1.088116\n",
       "cont3   0.308463 -0.362960  -1.838414 -1.241144  0.781711\n",
       "cont4  -0.966433  1.574703   0.505668  1.277541  1.304526\n",
       "cont5   1.155671 -0.495239   1.536780 -1.144258 -0.384343\n",
       "cont6  -0.319150 -0.314127   1.073306 -0.889242 -0.547768\n",
       "cont7   0.324519 -1.505026  -0.588210 -1.560941  0.153452\n",
       "cont8  -0.139562 -1.022767  -0.477780  0.283176  1.991112\n",
       "cont9   1.432335 -0.838888   0.669739 -0.674801 -0.086206\n",
       "cont10  0.661177  1.082046   0.994891 -1.533345  1.303600\n",
       "cont11  0.707830 -1.819822   0.508727 -0.128344  0.851442\n",
       "cont12  1.437093 -1.103376  -0.424387 -1.314553  1.663873\n",
       "cont13  1.245853  1.484426   0.197321 -1.219126 -0.079826"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.1: Predict using Stacking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def cv_score(model, X, y, scoring_method=\"neg_mean_squared_error\", shuffle=True, k=5):\n",
    "    \n",
    "    kfolds = KFold(n_splits=k, \n",
    "                  shuffle=shuffle,\n",
    "                  random_state=42)\n",
    "    \n",
    "    return cross_val_score(model, \n",
    "                            X, y, \n",
    "                            scoring=scoring_method,\n",
    "                            cv = kfolds)\n",
    "\n",
    "def rmse_score(model, X_train, y_train, X_valid, y_valid, **kwargs):\n",
    "        model.fit(X_train, y_train, **kwargs)\n",
    "        predictions = model.predict(X_valid)\n",
    "        \n",
    "        return mean_squared_error(predictions, y_valid, squared=False)\n",
    "\n",
    "   \n",
    "def kfold_train_predict(model, X, y, X_test,k=5, shuffle=True, use_eval_set=False, **kwargs):\n",
    "    \n",
    "    kfolds = KFold(n_splits=k, \n",
    "                  shuffle=shuffle,\n",
    "                  random_state=42)\n",
    "    \n",
    "    test_predictions = 0\n",
    "    t_valid_predictions = np.zeros_like(np.array(y))\n",
    "    valid_mean_score = [] \n",
    "    \n",
    "    for fold, (train_index, valid_index) in enumerate(kfolds.split(X)):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        model = clone(model)\n",
    "        \n",
    "        if use_eval_set:\n",
    "            model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], **kwargs)\n",
    "        else:\n",
    "            model.fit(X_train, y_train, **kwargs)\n",
    "        \n",
    "        # validation score\n",
    "        valid_predications = model.predict(X_valid)\n",
    "        score = mean_squared_error(valid_predications, y_valid, squared=False)\n",
    "        valid_mean_score.append(score)\n",
    "        \n",
    "        t_valid_predictions[valid_index] = valid_predications\n",
    "        # test predictions\n",
    "        test_predictions += model.predict(X_test) / k\n",
    "        \n",
    "        print('Fold:{} score:{:.4f}'.format(fold + 1, score))\n",
    "        \n",
    "    print('average score:{:.4f} ({:.4f})'.format(np.mean(valid_mean_score), np.std(valid_mean_score) ))\n",
    "    return test_predictions, t_valid_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lasso\n",
    "lasso = make_pipeline(PowerTransformer(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "# Elastic net\n",
    "e_net = make_pipeline(PowerTransformer(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "# gradient boosing\n",
    "gb = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, \n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "xgb_params = {'n_estimators': 10000,\n",
    "              'learning_rate': 0.35,\n",
    "              'subsample': 0.926,\n",
    "              'colsample_bytree': 0.84,\n",
    "              'max_depth': 2,\n",
    "              'booster': 'gbtree', \n",
    "              'reg_lambda': 35.1,\n",
    "              'reg_alpha': 34.9,\n",
    "              'random_state': 42,\n",
    "              'n_jobs': 4}\n",
    "\n",
    "xgb =  XGBRegressor(**xgb_params)\n",
    "\n",
    "\n",
    "catb = CatBoostRegressor(iterations=6800,\n",
    "                  learning_rate=0.93,\n",
    "                  loss_function=\"RMSE\",\n",
    "                  random_state=42,\n",
    "                  verbose=0,\n",
    "                  thread_count=4,\n",
    "                  depth=1,\n",
    "                  l2_leaf_reg=3.28)\n",
    "\n",
    "SEED = 7770777\n",
    "params_lgb = {\n",
    "    \"n_estimators\": 10000,   \n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.007899156646724397,\n",
    "    \"num_leaves\": 77,\n",
    "    \"max_depth\": 77,\n",
    "    \"feature_fraction\": 0.2256038826485174,\n",
    "    \"bagging_fraction\": 0.7705303688019942,\n",
    "    \"min_child_samples\": 290,\n",
    "    \"reg_alpha\": 9.562925363678952,\n",
    "    \"reg_lambda\": 9.355810045480153,\n",
    "    \"max_bin\": 772,\n",
    "    \"min_data_per_group\": 177,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"cat_smooth\": 96,\n",
    "    \"cat_l2\": 17,\n",
    "    \"verbosity\": -1,\n",
    "    \"bagging_seed\": SEED,\n",
    "    \"feature_fraction_seed\": SEED,\n",
    "    \"verbose_eval\":1000,\n",
    "    \"seed\": SEED\n",
    "}\n",
    "\n",
    "lgb = LGBMRegressor(**params_lgb)\n",
    "\n",
    "#                    objective='regression',\n",
    "#                    boosting_type=\"gbdt\"\n",
    "#                    learning_rate=0.01, \n",
    "#                    n_estimators=10000, \n",
    "#                    eval_set=[(X_valid, y_valid)],\n",
    "#                    early_stopping_rounds=200,\n",
    "#                    eval_metric='RMSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.7414 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline scores of each model\n",
    "score_ = rmse_score(lasso, X_train.values, y_train.values, X_valid.values, y_valid.values)\n",
    "print(\"\\nLasso score: {:.4f} \\n\".format(score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ = rmse_score(e_net, X_train, y_train, X_valid, y_valid)\n",
    "print(\"ElasticNet score: {:.4f} \\n\".format(score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ = rmse_score(xgb, X_train, y_train, X_valid, y_valid, early_stopping_rounds=200,\n",
    "                   eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "print(\"Xgboost score: {:.4f} \\n\".format(score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ = rmse_score(lgb, X_train, y_train, X_valid, y_valid, \n",
    "                   eval_set=[(X_valid, y_valid)], \n",
    "                   early_stopping_rounds=200, verbose=False)\n",
    "print(\"LGBM score: {:.4f} \\n\" .format(score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ = rmse_score(catb, X_train, y_train, X_valid, y_valid)\n",
    "print(\"CatBoostRegressor score: {:.4f} \\n\" .format(score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First approach: simple averaging of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorsMixer(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models, kwargs, weights):\n",
    "        self.models = [clone(model) for model in models]\n",
    "        self.weights = weights\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for model, kwargs in zip(self.models, self.kwargs):\n",
    "            \n",
    "            model.fit(X, y, **kwargs)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models])\n",
    "        return np.sum(predictions * self.weights, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_regressors = RegressorsMixer(models=[lgb, xgb, catb],\n",
    "                                 kwargs=[\n",
    "                                         {'early_stopping_rounds':100,'eval_set':[(X_valid, y_valid)],'verbose':False},\n",
    "                                         {'early_stopping_rounds':100,'eval_set':[(X_valid, y_valid)],'verbose':False},\n",
    "                                           {}],\n",
    "                                 weights=[0.30, 0.40, 0.30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ = rmse_score(mix_regressors, X_train, y_train, X_valid, y_valid)\n",
    "print(\"Averaged score from mix of models: {:.4f} \\n\" .format(score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second approach: simple averaging of predictions with folds on each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach I am going to run k-folds using each model and average the rest results among folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7385\n",
      "Fold:2 score:0.7383\n",
      "Fold:3 score:0.7397\n",
      "Fold:4 score:0.7394\n",
      "Fold:5 score:0.7398\n",
      "average score:0.7391 (0.0006)\n"
     ]
    }
   ],
   "source": [
    "lasso_test_results, lasso_valid_results = kfold_train_predict(lasso, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7385\n",
      "Fold:2 score:0.7383\n",
      "Fold:3 score:0.7397\n",
      "Fold:4 score:0.7394\n",
      "Fold:5 score:0.7398\n",
      "average score:0.7391 (0.0006)\n"
     ]
    }
   ],
   "source": [
    "enet_test_results, enet_valid_results = kfold_train_predict(e_net, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1 score:0.7164\n",
      "Fold:2 score:0.7164\n"
     ]
    }
   ],
   "source": [
    "xgb_test_results, xgb_valid_results = kfold_train_predict(xgb, X, y, X_test, use_eval_set=True,\n",
    "                   early_stopping_rounds=200,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_test_results, lgb_valid_results = kfold_train_predict(lgb, X, y, X_test, use_eval_set=True,\n",
    "                   early_stopping_rounds=200,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catb_test_results, catb_valid_results = kfold_train_predict(catb, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_test_results, mix_valid_results = kfold_train_predict(catb, X, y, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above, we set `squared=False` to get the root mean squared error (RMSE) on the validation data.\n",
    "\n",
    "# Step 5: Submit to the competition\n",
    "\n",
    "We'll begin by using the trained model to generate predictions, which we'll save to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = mix_regressors\n",
    "# Use the model to generate predictions\n",
    "#best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-16T22:54:17.068352Z",
     "iopub.status.idle": "2021-08-16T22:54:17.068911Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = xgb_results\n",
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'target': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.072649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8.408605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>8.371366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>8.495113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>8.143530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>8.290678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>8.514958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>7.860616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>8.082018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>8.302702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    target\n",
       "0   0  8.072649\n",
       "1   5  8.408605\n",
       "2  15  8.371366\n",
       "3  16  8.495113\n",
       "4  17  8.143530\n",
       "5  19  8.290678\n",
       "6  20  8.514958\n",
       "7  21  7.860616\n",
       "8  23  8.082018\n",
       "9  29  8.302702"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
