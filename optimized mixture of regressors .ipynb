{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the **[30 Days of ML competition](https://www.kaggle.com/c/30-days-of-ml/overview)**!  In this notebook, you'll learn how to make your first submission.\n",
    "\n",
    "Before getting started, make your own editable copy of this notebook by clicking on the **Copy and Edit** button.\n",
    "\n",
    "# Step 1: Import helpful libraries\n",
    "\n",
    "We begin by importing the libraries we'll need.  Some of them will be familiar from the **[Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)** course and the **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:09.725137Z",
     "iopub.status.busy": "2021-08-16T22:55:09.724708Z",
     "iopub.status.idle": "2021-08-16T22:55:09.73297Z",
     "shell.execute_reply": "2021-08-16T22:55:09.731277Z",
     "shell.execute_reply.started": "2021-08-16T22:55:09.725102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Familiar imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "\n",
    "\n",
    "# For ordinal encoding categorical variables, splitting data, pipeline, and so on\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, PowerTransformer, StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# For training random forest model\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# base\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the data\n",
    "\n",
    "Next, we'll load the training and test data.  \n",
    "\n",
    "We set `index_col=0` in the code cell below to use the `id` column to index the DataFrame.  (*If you're not sure how this works, try temporarily removing `index_col=0` and see how it changes the result.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:10.592447Z",
     "iopub.status.busy": "2021-08-16T22:55:10.591978Z",
     "iopub.status.idle": "2021-08-16T22:55:14.91458Z",
     "shell.execute_reply": "2021-08-16T22:55:14.912747Z",
     "shell.execute_reply.started": "2021-08-16T22:55:10.592407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.527335</td>\n",
       "      <td>0.230599</td>\n",
       "      <td>-0.118039</td>\n",
       "      <td>0.405965</td>\n",
       "      <td>0.497053</td>\n",
       "      <td>0.668060</td>\n",
       "      <td>1.058443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.460926</td>\n",
       "      <td>0.214003</td>\n",
       "      <td>-0.069309</td>\n",
       "      <td>0.310494</td>\n",
       "      <td>0.427903</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.887253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.490498</td>\n",
       "      <td>0.253346</td>\n",
       "      <td>-0.056104</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.502462</td>\n",
       "      <td>0.647512</td>\n",
       "      <td>1.034704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>0.219199</td>\n",
       "      <td>0.130676</td>\n",
       "      <td>0.329783</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.664451</td>\n",
       "      <td>1.039560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.491654</td>\n",
       "      <td>0.240074</td>\n",
       "      <td>0.255908</td>\n",
       "      <td>0.284188</td>\n",
       "      <td>0.390470</td>\n",
       "      <td>0.696599</td>\n",
       "      <td>1.055424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.510526</td>\n",
       "      <td>0.228232</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>0.354141</td>\n",
       "      <td>0.488865</td>\n",
       "      <td>0.669625</td>\n",
       "      <td>1.067649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.467476</td>\n",
       "      <td>0.210331</td>\n",
       "      <td>-0.224689</td>\n",
       "      <td>0.342873</td>\n",
       "      <td>0.429383</td>\n",
       "      <td>0.573383</td>\n",
       "      <td>1.111552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.537119</td>\n",
       "      <td>0.218140</td>\n",
       "      <td>0.203763</td>\n",
       "      <td>0.355825</td>\n",
       "      <td>0.504661</td>\n",
       "      <td>0.703441</td>\n",
       "      <td>1.032837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.498456</td>\n",
       "      <td>0.239920</td>\n",
       "      <td>-0.260275</td>\n",
       "      <td>0.332486</td>\n",
       "      <td>0.439151</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>1.040229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.474872</td>\n",
       "      <td>0.218007</td>\n",
       "      <td>0.117896</td>\n",
       "      <td>0.306874</td>\n",
       "      <td>0.434620</td>\n",
       "      <td>0.614333</td>\n",
       "      <td>0.982922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.474492</td>\n",
       "      <td>0.255949</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>0.276017</td>\n",
       "      <td>0.459975</td>\n",
       "      <td>0.691579</td>\n",
       "      <td>1.055960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.473216</td>\n",
       "      <td>0.222022</td>\n",
       "      <td>0.052608</td>\n",
       "      <td>0.308151</td>\n",
       "      <td>0.433812</td>\n",
       "      <td>0.642057</td>\n",
       "      <td>1.071444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.494561</td>\n",
       "      <td>0.247292</td>\n",
       "      <td>-0.074208</td>\n",
       "      <td>0.289074</td>\n",
       "      <td>0.422887</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>0.975035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.508273</td>\n",
       "      <td>0.222950</td>\n",
       "      <td>0.151050</td>\n",
       "      <td>0.300669</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.758447</td>\n",
       "      <td>0.905992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>8.241979</td>\n",
       "      <td>0.746555</td>\n",
       "      <td>0.140329</td>\n",
       "      <td>7.742071</td>\n",
       "      <td>8.191373</td>\n",
       "      <td>8.728634</td>\n",
       "      <td>10.411992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std       min       25%       50%       75%  \\\n",
       "cont0   300000.0  0.527335  0.230599 -0.118039  0.405965  0.497053  0.668060   \n",
       "cont1   300000.0  0.460926  0.214003 -0.069309  0.310494  0.427903  0.615113   \n",
       "cont2   300000.0  0.490498  0.253346 -0.056104  0.300604  0.502462  0.647512   \n",
       "cont3   300000.0  0.496689  0.219199  0.130676  0.329783  0.465026  0.664451   \n",
       "cont4   300000.0  0.491654  0.240074  0.255908  0.284188  0.390470  0.696599   \n",
       "cont5   300000.0  0.510526  0.228232  0.045915  0.354141  0.488865  0.669625   \n",
       "cont6   300000.0  0.467476  0.210331 -0.224689  0.342873  0.429383  0.573383   \n",
       "cont7   300000.0  0.537119  0.218140  0.203763  0.355825  0.504661  0.703441   \n",
       "cont8   300000.0  0.498456  0.239920 -0.260275  0.332486  0.439151  0.606056   \n",
       "cont9   300000.0  0.474872  0.218007  0.117896  0.306874  0.434620  0.614333   \n",
       "cont10  300000.0  0.474492  0.255949  0.048732  0.276017  0.459975  0.691579   \n",
       "cont11  300000.0  0.473216  0.222022  0.052608  0.308151  0.433812  0.642057   \n",
       "cont12  300000.0  0.494561  0.247292 -0.074208  0.289074  0.422887  0.714502   \n",
       "cont13  300000.0  0.508273  0.222950  0.151050  0.300669  0.472400  0.758447   \n",
       "target  300000.0  8.241979  0.746555  0.140329  7.742071  8.191373  8.728634   \n",
       "\n",
       "              max  \n",
       "cont0    1.058443  \n",
       "cont1    0.887253  \n",
       "cont2    1.034704  \n",
       "cont3    1.039560  \n",
       "cont4    1.055424  \n",
       "cont5    1.067649  \n",
       "cont6    1.111552  \n",
       "cont7    1.032837  \n",
       "cont8    1.040229  \n",
       "cont9    0.982922  \n",
       "cont10   1.055960  \n",
       "cont11   1.071444  \n",
       "cont12   0.975035  \n",
       "cont13   0.905992  \n",
       "target  10.411992  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "\n",
    "# Preview the data\n",
    "train.head()\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell separates the target (which we assign to `y`) from the training features (which we assign to `features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:14.916952Z",
     "iopub.status.busy": "2021-08-16T22:55:14.916515Z",
     "iopub.status.idle": "2021-08-16T22:55:14.984676Z",
     "shell.execute_reply": "2021-08-16T22:55:14.98316Z",
     "shell.execute_reply.started": "2021-08-16T22:55:14.916916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat0</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat1</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat2</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat3</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat4</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat5</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat6</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat7</th>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat8</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat9</th>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>0.20147</td>\n",
       "      <td>0.743068</td>\n",
       "      <td>0.742708</td>\n",
       "      <td>0.429551</td>\n",
       "      <td>1.05829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>-0.0148218</td>\n",
       "      <td>0.367411</td>\n",
       "      <td>0.310383</td>\n",
       "      <td>0.620998</td>\n",
       "      <td>0.367492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>0.669699</td>\n",
       "      <td>1.02161</td>\n",
       "      <td>-0.0126728</td>\n",
       "      <td>0.577942</td>\n",
       "      <td>-0.0523886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>0.136278</td>\n",
       "      <td>0.365798</td>\n",
       "      <td>0.576957</td>\n",
       "      <td>0.28061</td>\n",
       "      <td>0.232407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>0.610706</td>\n",
       "      <td>0.276853</td>\n",
       "      <td>0.285074</td>\n",
       "      <td>0.284667</td>\n",
       "      <td>0.287595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.533087</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.66898</td>\n",
       "      <td>0.686964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>0.160266</td>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.420667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.732948</td>\n",
       "      <td>0.648182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>0.38947</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.679618</td>\n",
       "      <td>0.684501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.956692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.34601</td>\n",
       "      <td>1.00077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.71461</td>\n",
       "      <td>0.776742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.54015</td>\n",
       "      <td>0.625849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>0.86985</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>0.763846</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>0.250823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id              1         2          3         4          6\n",
       "cat0            B         B          A         B          A\n",
       "cat1            B         B          A         B          A\n",
       "cat2            B         A          A         A          A\n",
       "cat3            C         A          C         C          C\n",
       "cat4            B         B          B         B          B\n",
       "cat5            B         D          D         D          D\n",
       "cat6            A         A          A         A          A\n",
       "cat7            E         F          D         E          E\n",
       "cat8            C         A          A         C          A\n",
       "cat9            N         O          F         K          N\n",
       "cont0     0.20147  0.743068   0.742708  0.429551    1.05829\n",
       "cont1  -0.0148218  0.367411   0.310383  0.620998   0.367492\n",
       "cont2    0.669699   1.02161 -0.0126728  0.577942 -0.0523886\n",
       "cont3    0.136278  0.365798   0.576957   0.28061   0.232407\n",
       "cont4    0.610706  0.276853   0.285074  0.284667   0.287595\n",
       "cont5    0.400361  0.533087   0.650609   0.66898   0.686964\n",
       "cont6    0.160266  0.558922   0.375348  0.239061   0.420667\n",
       "cont7    0.310921  0.516294   0.902567  0.732948   0.648182\n",
       "cont8     0.38947  0.594928   0.555205  0.679618   0.684501\n",
       "cont9    0.267559  0.341439   0.843531  0.574844   0.956692\n",
       "cont10   0.237281  0.906013   0.748809   0.34601    1.00077\n",
       "cont11   0.377873  0.921701   0.620126   0.71461   0.776742\n",
       "cont12   0.322401  0.261975   0.541474   0.54015   0.625849\n",
       "cont13    0.86985  0.465083   0.763846  0.280682   0.250823"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate target from features\n",
    "y = train['target']\n",
    "features = train.drop(['target'], axis=1)\n",
    "\n",
    "# Preview features\n",
    "features.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the data\n",
    "\n",
    "Next, we'll need to handle the categorical columns (`cat0`, `cat1`, ... `cat9`).  \n",
    "\n",
    "In the **[Categorical Variables lesson](https://www.kaggle.com/alexisbcook/categorical-variables)** in the Intermediate Machine Learning course, you learned several different ways to encode categorical variables in a dataset.  In this notebook, we'll use ordinal encoding and save our encoded features as new variables `X` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_poly_features(train, test, cols=None, concate=True, poly_degree=2):\n",
    "    \n",
    "    if cols is  None:\n",
    "        cols = train.columns\n",
    "     \n",
    "    columns = train[cols].columns\n",
    "    poly = PolynomialFeatures(poly_degree)\n",
    "    poly_train = pd.DataFrame(poly.fit_transform(train[cols]), index=train.index)\n",
    "    poly_test = pd.DataFrame(poly.transform(test[cols]), index=test.index)\n",
    "    \n",
    "    # stamp these columns\n",
    "    poly_train = poly_train.add_prefix('poly_')\n",
    "    poly_test = poly_test.add_prefix('poly_')\n",
    "    \n",
    "    if concate:\n",
    "        train = pd.concat([train, poly_train], axis=1)\n",
    "        test = pd.concat([test, poly_test], axis=1)\n",
    "        \n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:17.707975Z",
     "iopub.status.busy": "2021-08-16T22:55:17.7076Z",
     "iopub.status.idle": "2021-08-16T22:55:19.670568Z",
     "shell.execute_reply": "2021-08-16T22:55:19.669219Z",
     "shell.execute_reply.started": "2021-08-16T22:55:17.707941Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of categorical columns\n",
    "object_cols_long = [col for col in features.columns if 'cat' in col]\n",
    "cont_cols = [col for col in features.columns if 'con' in col]\n",
    "\n",
    "X = features.copy()\n",
    "X_test = test.copy()\n",
    "\n",
    "# cols = ['cont0', 'cont3', 'cont9']\n",
    "# add poly features\n",
    "# X, X_test = add_poly_features(X, X_test, cols)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we break off a validation set from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:29.309502Z",
     "iopub.status.busy": "2021-08-16T22:55:29.309037Z",
     "iopub.status.idle": "2021-08-16T22:55:29.774149Z",
     "shell.execute_reply": "2021-08-16T22:55:29.772853Z",
     "shell.execute_reply.started": "2021-08-16T22:55:29.309468Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225000, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfomration: scaling, encoding, new features, ... etc\n",
    "# helpers\n",
    "# map columns to indexes \n",
    "\n",
    "class ML30Transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, \n",
    "                 cat_columns=None,\n",
    "                 cont_columns=None,\n",
    "                 target_column=None,\n",
    "                 scaler=StandardScaler(),\n",
    "                 normalizer=None,\n",
    "                 cont_encoder=None,\n",
    "                 cat_encoder=OrdinalEncoder(),\n",
    "                 target_encoder=None):\n",
    "        \n",
    "        self.cat_columns = cat_columns\n",
    "        self.cont_columns = cont_columns\n",
    "        self.target_column = target_column\n",
    "        self.scaler = scaler\n",
    "        self.normalizer = normalizer\n",
    "        self.cat_encoder = cat_encoder\n",
    "        self.cont_encoder = cont_encoder\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "        self.cat_encoder.fit(X[self.cat_columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        return self.cat_encoder.transform(X[self.cat_columns])\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "ml30_transformer = OrdinalEncoder()\n",
    "#ML30Transformer(cont_columns=X.columns.get_indexer(cont_cols))\n",
    "X[object_cols_long] = ml30_transformer.fit_transform(X[object_cols_long])\n",
    "X_test[object_cols_long] = ml30_transformer.transform(X_test[object_cols_long])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4.1: Predict using Generalized Stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# helpers and wrappers\n",
    "\n",
    "## helper fucntions\n",
    "def store_oof_predictions(model_name,\n",
    "                          valid_predictions,\n",
    "                          test_predictions,\n",
    "                          X_train,\n",
    "                          X_test,\n",
    "                          stacking_level,\n",
    "                          output_folder,\n",
    "                          n_folds, \n",
    "                          random_state):    \n",
    "    \n",
    "    \"\"\"\n",
    "    Store oof predictions into files.\n",
    "    It is safe not to use defaults for this helper to make sure \n",
    "    we are storing the right experiement. \n",
    "    \"\"\"\n",
    "    \n",
    "    if test_predictions is not None:\n",
    "        test_df = pd.DataFrame({'Id': X_test.index,\n",
    "                       model_name: test_predictions})\n",
    "        test_df.to_csv( f'{output_folder}{os.sep}{model_name}_{n_folds}_test.csv',\n",
    "                       index=False)\n",
    "\n",
    "    if valid_predictions is not None:\n",
    "        valid_df = pd.DataFrame({'Id': X_train.index,\n",
    "                           model_name: valid_predictions})\n",
    "        valid_df.to_csv(f'{output_folder}{os.sep}{model_name}_{n_folds}_valid.csv', \n",
    "                        index=False)\n",
    "    \n",
    "    \n",
    "def read_oof_predictions(pattern, \n",
    "                     models_names, \n",
    "                     index='id'):    \n",
    "    \"\"\"\n",
    "    Read files according the pattern in their name\n",
    "    it returns a dataframe where each column is the prediction of a model\n",
    "    \"\"\"\n",
    "    li = [] \n",
    "    for f in glob.glob(pattern):\n",
    "        file_name = f.split(os.sep)[-1] # get file name only\n",
    "        print(file_name)\n",
    "        if file_name.lower().startswith(tuple(s.lower() for s in models_names)): # get only required models\n",
    "            df = pd.read_csv(f, index_col=0)\n",
    "            li.append(df)\n",
    "    \n",
    "                                   \n",
    "    return pd.concat(li, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper():\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 name,\n",
    "                 uses_eval_set=False,\n",
    "                 fit_params={}):\n",
    "        \n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        \n",
    "        self.uses_eval_set = uses_eval_set\n",
    "        self.fit_params = fit_params # any extra params for the 'fit' function\n",
    "        \n",
    "#         self.valid_predictions = None # oof predictions on the valiation set\n",
    "#         self.test_predictions = None  # meta-features on the test set\n",
    "                \n",
    "    def fit(self, X, y, eval_set=None):\n",
    "        if self.uses_eval_set:\n",
    "            self.model.fit(X, y, eval_set=eval_set, **(self.fit_params))\n",
    "        else:\n",
    "            self.model.fit(X, y, **(self.fit_params)) \n",
    "        return self\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "    def clone_me(self, random_state=None):\n",
    "        wrapper = ModelWrapper(model=clone(self.model), # clone from sklean.base\n",
    "                               name=self.name, \n",
    "                               uses_eval_set=self.uses_eval_set,\n",
    "                               fit_params=self.fit_params)\n",
    "        wrapper.name = self.name\n",
    "        if random_state is not None:\n",
    "            wrapper.set_random_state(random_state)\n",
    "        \n",
    "        return wrapper\n",
    "    \n",
    "    def set_random_state(self, random_state):\n",
    "        if hasattr(self.model, 'random_state'):\n",
    "            self.model.random_state = random_state\n",
    "        elif hasattr(self.model, 'random_seed'):\n",
    "            self.model.random_seed = random_state\n",
    "            \n",
    "    def get_random_state(self):\n",
    "        if hasattr(self.model, 'random_state'):\n",
    "            return self.model.random_state \n",
    "        elif hasattr(self.model, 'random_seed'):\n",
    "            return self.model.random_seed\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "    def __init__(self,\n",
    "                  model: ModelWrapper):\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "    def calc_oofs(self,\n",
    "                  X, y,\n",
    "                  X_test,\n",
    "                  folds,\n",
    "                  transformer=None,\n",
    "                  verbose=False,\n",
    "                  use_different_random_states=True):\n",
    "        \"\"\"\n",
    "        Return the oofs predictions and the meta features (test predictions)\n",
    "        \"\"\"\n",
    "        \n",
    "        test_predictions = 0\n",
    "        oof_predictions = np.zeros_like(np.array(y))\n",
    "        valid_mean_score = [] \n",
    "                \n",
    "        for fold, (train_ix, valid_ix) in enumerate(folds.split(X)):\n",
    "            X_train, X_valid = X[train_ix], X[valid_ix]\n",
    "            y_train, y_valid = y[train_ix], y[valid_ix]\n",
    "            \n",
    "            print(len(train_ix), len(valid_ix))\n",
    "            \n",
    "            # transform input\n",
    "            \n",
    "            if transformer is not None:\n",
    "                X_train = transformer.fit_transform(X_train)\n",
    "                X_valid = transformer.transform(X_valid)\n",
    "\n",
    "            \n",
    "            # check if we train each fold on differently initialized clone\n",
    "            if use_different_random_states:\n",
    "                model = self.model.clone_me(random_state=fold)\n",
    "            else:\n",
    "                model = self.model.clone_me()\n",
    "            \n",
    "            # fit the model\n",
    "            if model.uses_eval_set:\n",
    "                model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "            ## predictions\n",
    "            # on the validation set\n",
    "            valid_predications = model.predict(X_valid)\n",
    "            score = mean_squared_error(valid_predications, y_valid, squared=False)\n",
    "            valid_mean_score.append(score)\n",
    "            oof_predictions[valid_ix] = valid_predications\n",
    "            \n",
    "            # on the test set\n",
    "            # transform it first on a copy\n",
    "            X_test_ = transformer.transform(X_test)\n",
    "            test_predictions += model.predict(X_test_) / folds.n_splits\n",
    "            \n",
    "            if verbose:\n",
    "                print('Fold:{} score:{:.4f}'.format(fold + 1, score))\n",
    "        \n",
    "        if verbose:\n",
    "            print('Average score:{:.4f} ({:.4f})'.format(np.mean(valid_mean_score), np.std(valid_mean_score) ))\n",
    "    \n",
    "        return oof_predictions, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Experiment():\n",
    "    def __init__(self,\n",
    "                 title='Experiment',\n",
    "                 n_folds=3,\n",
    "                 random_state=42,\n",
    "                 shuffle=True,\n",
    "                 use_different_random_states=True,\n",
    "                 main_folder=os.getcwd()):\n",
    "        \n",
    "        self.title = title\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "        self.shuffle = shuffle\n",
    "        self.use_different_random_states = use_different_random_states\n",
    "        self.main_folder = main_folder\n",
    "        \n",
    "        \n",
    "\n",
    "    def create(self, use_folder=None, resume=False):\n",
    "        \n",
    "        # create folds\n",
    "        self.folds = KFold(n_splits=self.n_folds, \n",
    "                           random_state=self.random_state,\n",
    "                           shuffle=self.shuffle)\n",
    "        \n",
    "        \n",
    "        # create time stamp and subfolder with the current time stamp\n",
    "        if use_folder is not None:\n",
    "            self.output_folder = use_folder \n",
    "        else:\n",
    "            time_stamp = datetime.now().isoformat(' ', 'seconds')\n",
    "            self.output_folder = self.title + ' ' + time_stamp.replace(':', '-')\n",
    "            Path(f'{self.main_folder}{os.sep}{self.output_folder}').mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "     \n",
    "    def to_dict(self):\n",
    "        \n",
    "        return dict({\"title\": self.title,\n",
    "                    \"n_folds\": self.n_folds,\n",
    "                    \"random_state\": self.random_state,\n",
    "                    \"use_different_random_states\": self.use_different_random_states,\n",
    "                    \"main_folder\": self.main_folder,\n",
    "                    \"output_folder\": self.output_folder})\n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        return str(self.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LevelTrainer():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 experiment, # Experiment,\n",
    "                 models,      # ModelWrapper\n",
    "                 transformer, # data transformer\n",
    "                 level_num=1):\n",
    "        \n",
    "        self.level_num = level_num\n",
    "        self.experiment = experiment\n",
    "        self.models = models\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def train(self, X_df, y_df, X_test_df, verbose=True):\n",
    "        \n",
    "        assert models is not None\n",
    "        \n",
    "\n",
    "        for model_wrapper in self.models:\n",
    "            \n",
    "            if verbose:\n",
    "                print('-'*3)\n",
    "                print(f'Model:{model_wrapper.name}')\n",
    "                print('-'*3)\n",
    "                \n",
    "            trainer = ModelTrainer(model_wrapper)\n",
    "            oof_preds, test_preds = trainer.calc_oofs(X.values, y.values,\n",
    "                                                      X_test.values,\n",
    "                                                      transformer=self.transformer,\n",
    "                                                      folds=self.experiment.folds,\n",
    "                                                      verbose=verbose,\n",
    "                                                      use_different_random_states=self.experiment.use_different_random_states)\n",
    "            # store predictions\n",
    "            store_oof_predictions(model_name=model_wrapper.name,\n",
    "                                  valid_predictions=oof_preds,\n",
    "                                  test_predictions=test_preds,\n",
    "                                  X_train=X_df,\n",
    "                                  X_test=X_test_df,\n",
    "                                  stacking_level=self.level_num, \n",
    "                                  n_folds=self.experiment.n_folds, \n",
    "                                  random_state=model_wrapper.get_random_state(),\n",
    "                                  output_folder=f'{self.experiment.main_folder}{os.sep}{self.experiment.output_folder}')\n",
    "            if verbose:\n",
    "                print('-'*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamater ranges\n",
    "common ranges (to be added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters: these should go to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra-tree\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "# random forest\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "# xgboost\n",
    "# xgb_params = {'n_estimators': 10000,\n",
    "#               'learning_rate': 0.35,\n",
    "#               'subsample': 0.926,\n",
    "#               'colsample_bytree': 0.84,\n",
    "#               'max_depth': 2,\n",
    "#               'booster': 'gbtree', \n",
    "#               'reg_lambda': 35.1,\n",
    "#               'reg_alpha': 34.9,\n",
    "#               'random_state': 42,\n",
    "#               'n_jobs': -1}\n",
    "\n",
    "# Using optuna but still rough\n",
    "xgb_params = {'max_depth': 5,\n",
    "             'learning_rate': 0.021252439960137114,\n",
    "             'n_estimators': 13500,\n",
    "             'subsample': 0.62,\n",
    "             'booster': 'gbtree',\n",
    "             'colsample_bytree': 0.1,\n",
    "             'reg_lambda': 0.1584605320779582,\n",
    "             'reg_alpha': 15.715145781076245,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# catboost\n",
    "catb_params = {'iterations': 6800,\n",
    "              'learning_rate': 0.93,\n",
    "              'loss_function': \"RMSE\",\n",
    "              'random_state': 42,\n",
    "              'verbose': 0,\n",
    "              'thread_count': 4,\n",
    "              'depth': 1,\n",
    "              'l2_leaf_reg': 3.28}\n",
    "\n",
    "SEED = 7770777\n",
    "params_lgb = {\"n_estimators\": 10000,   \n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"learning_rate\": 0.007899156646724397,\n",
    "            \"num_leaves\": 77,\n",
    "            \"max_depth\": 77,\n",
    "            \"feature_fraction\": 0.2256038826485174,\n",
    "            \"bagging_fraction\": 0.7705303688019942,\n",
    "            \"min_child_samples\": 290,\n",
    "            \"reg_alpha\": 9.562925363678952,\n",
    "            \"reg_lambda\": 9.355810045480153,\n",
    "            \"max_bin\": 772,\n",
    "            \"min_data_per_group\": 177,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"cat_smooth\": 96,\n",
    "            \"cat_l2\": 17,\n",
    "            \"verbosity\": -1,\n",
    "            \"bagging_seed\": SEED,\n",
    "            \"feature_fraction_seed\": SEED,\n",
    "            \"verbose_eval\":1000,\n",
    "            \"seed\": SEED,\n",
    "            \"n_jobs\":-1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external hyperparamaters\n",
    "\n",
    "### fit function hyperparamaters\n",
    "# some models require special paramaters like early stoping in xgboost and lgbm\n",
    "\n",
    "# xgboost\n",
    "xgb_fit_params = {'early_stopping_rounds': 200,\n",
    "                  'verbose': False}\n",
    "\n",
    "# lgbm\n",
    "lgb_fit_params = {'early_stopping_rounds': 200,\n",
    "                  'verbose': False}\n",
    "\n",
    "### application/implementation paramaters\n",
    "# These paramaters are implementation dependent \n",
    "\n",
    "# xgboost\n",
    "xgb_app_params = {'uses_eval_set':True}\n",
    "\n",
    "# lgbm\n",
    "lgb_app_params = {'uses_eval_set':True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso\n",
    "lasso = Lasso(alpha =0.00005)\n",
    "\n",
    "# Elastic net\n",
    "e_net = ElasticNet(alpha=0.00005, l1_ratio=.9)\n",
    "\n",
    "# KNeighborsRegressor\n",
    "knn =  KNeighborsRegressor()\n",
    "\n",
    "# extra-tree\n",
    "extree = ExtraTreesRegressor(**et_params)\n",
    "\n",
    "# random forest\n",
    "rfr = RandomForestRegressor(**rf_params)\n",
    "\n",
    "# xgboost\n",
    "xgb =  XGBRegressor(**xgb_params)\n",
    "\n",
    "#catboost\n",
    "catb = CatBoostRegressor(**catb_params)\n",
    "\n",
    "#lgbm\n",
    "lgb = LGBMRegressor(**params_lgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all settings in one dictionary, \n",
    "# we can store/load it then to a JSON file\n",
    "models = {'Lasso': {\"model\":lasso, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'ElasticNet': {\"model\": e_net, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'ExtraTreesRegressor': {\"model\": extree, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'RandomForestRegressor': {\"model\": rfr, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'XGBRegressor': {\"model\": xgb, \"fit_kwargs\":xgb_fit_params, \"app_params\": xgb_app_params},\n",
    "          'CatBoostRegressor': {\"model\": catb, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'LGBMRegressor': {\"model\": lgb, \"fit_kwargs\":lgb_fit_params, \"app_params\": lgb_app_params}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking with two levels:\n",
    "we need two things:\n",
    "\n",
    "oof predictions and test results.\n",
    "- train level 1 models and collect their oof predictions \n",
    "- use oof predictions in another model and predict the final target.\n",
    "\n",
    "- there are some variations to this simple procedure: see \n",
    " - https://mlwave.com/kaggle-ensembling-guide/\n",
    " - https://www.kaggle.com/getting-started/18153#post103381\n",
    " \n",
    "- one approach would be to:\n",
    "    - train N models in the first level and get their oof predictions\n",
    "    - train a model on the whole train set and get it's predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings: experiment and stacking architecutre\n",
    "\n",
    "\n",
    "\n",
    "#level_1_models = ['CatBoostRegressor', 'LGBMRegressor']\n",
    "level_1_models = ['all'] # to select all models\n",
    "\n",
    "output_path = os.getcwd()\n",
    "\n",
    "ml30_experiment = Experiment(title='ML 30 days',\n",
    "                        n_folds=5,\n",
    "                        random_state=42,\n",
    "                        shuffle=True,\n",
    "                        use_different_random_states=True,\n",
    "                        main_folder=f'{output_path}{os.sep}Experiments')\n",
    "\n",
    "ml30_experiment.create(use_folder='ML 30 days 2021-08-23 17-02-31', resume=True)\n",
    "\n",
    "print(ml30_experiment)\n",
    "\n",
    "stack = { 'level_1_models': level_1_models, 'meta_model': 'XGBRegressor'}\n",
    "\n",
    "\n",
    "# if level_1_models is set to 'all' use the models\n",
    "if stack['level_1_models'][0].lower() == 'all':\n",
    "    level_1_models_names = models.keys()\n",
    "else: \n",
    "    level_1_models_names = stack['level_1_models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main procedure\n",
    "\n",
    "# create models\n",
    "model_wrappers = []\n",
    "\n",
    "for model_name in level_1_models_names:\n",
    "    \n",
    "    # get paramaters  \n",
    "    model = models[model_name]\n",
    "    fit_kwargs = models[model_name]['fit_kwargs']\n",
    "    app_params = models[model_name]['app_params']\n",
    "    \n",
    "    model_wrapper = ModelWrapper(model=model['model'], name=model_name)\n",
    "    if fit_kwargs is not None:\n",
    "        model_wrapper.fit_params = fit_kwargs\n",
    "    if app_params is not None:\n",
    "        model_wrapper.uses_eval_set = app_params['uses_eval_set']\n",
    "    model_wrappers.append(model_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train the levels\n",
    "ml30_transformer = ML30Transformer(cat_columns=X.columns.get_indexer(object_cols_long))\n",
    "\n",
    "level_trainer = LevelTrainer(experiment=ml30_experiment, \n",
    "                             models=model_wrappers, \n",
    "                             transformer=None)\n",
    "\n",
    "level_trainer.train(X_df=X, y_df=y, X_test_df=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "                         \n",
    "# required results                            \n",
    "fold_id = 5\n",
    "folder ='Experiments/ML 30 days 2021-08-23 17-02-31'\n",
    "                            \n",
    "level_1_models = [\n",
    "                  'ExtraTreesRegressor',\n",
    "                  'LGBMRegressor',\n",
    "                  'CatBoostRegressor',\n",
    "                  'ElasticNet'\n",
    "                  ]\n",
    "\n",
    "meta_regressor = 'CatBoostRegressor'\n",
    "\n",
    "\n",
    "\n",
    "# new features \n",
    "X_train_ = read_oof_predictions(pattern=f\"{folder}{os.sep}*{fold_id}_valid.csv\",\n",
    "                           models_names=level_1_models)\n",
    "X_test_ = read_oof_predictions(pattern=f\"{folder}{os.sep}*{fold_id}_test.csv\",\n",
    "                          models_names=level_1_models)\n",
    "\n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = ModelWrapper(lasso, name='Meta')\n",
    "model_trainer = ModelTrainer(meta_model)\n",
    "\n",
    "meta_valid_results, meta_test_results = model_trainer.calc_oofs(X_train_.values, \n",
    "                                                                y.values, \n",
    "                                                                X_test_.values,\n",
    "                                                                experiment.folds, \n",
    "                                                                verbose=True,\n",
    "                                                                use_different_random_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = np.exp((np.log(lasso_test_results) + np.log(xgb_test_results) + np.log(lgb_test_results) + np.log(catb_test_results)) / 4 )\n",
    "results = np.exp(np.sum(np.log(np.column_stack(test_stack)) / 4, axis=1))\n",
    "#mean_squared_error(y, y3, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = meta_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above, we set `squared=False` to get the root mean squared error (RMSE) on the validation data.\n",
    "\n",
    "# Step 5: Submit to the competition\n",
    "\n",
    "We'll begin by using the trained model to generate predictions, which we'll save to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-16T22:54:17.068352Z",
     "iopub.status.idle": "2021-08-16T22:54:17.068911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'target': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
