{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook describes how to structure the project.\n",
    "\n",
    "During the competition there were many tasks to do, plan, research, test, tune, accept disappointment of failed tests, and be happy with a little improvement. \n",
    "\n",
    "Therefore, the workspace and the files of the project should be structured in a flexible way with less repeated code. In other word, is to split code from data/configuration to save time and reduce errors/bugs and avoid copy/paste.\n",
    "\n",
    "Therefore, first we define the entities in the project.\n",
    "There are four main entities and I think these will be the same in all projects: experiment, model, level, and stack. These will be modeled by classes as described in this notebook.\n",
    "\n",
    "\n",
    "*This is a draft work, and will be improved regularly.*\n",
    "\n",
    "\n",
    "I would like to give credits to many kernels and websites among them:\n",
    "\n",
    " - Good introduction introduction about stacking: https://mlwave.com/kaggle-ensembling-guide/\n",
    " - https://www.kaggle.com/getting-started/18153#post103381\n",
    " - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:09.725137Z",
     "iopub.status.busy": "2021-08-16T22:55:09.724708Z",
     "iopub.status.idle": "2021-08-16T22:55:09.73297Z",
     "shell.execute_reply": "2021-08-16T22:55:09.731277Z",
     "shell.execute_reply.started": "2021-08-16T22:55:09.725102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Familiar imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For ordinal encoding categorical variables, splitting data, pipeline, and so on\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, PowerTransformer, StandardScaler, \\\n",
    "                                  MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# For training random forest model\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# base\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:10.592447Z",
     "iopub.status.busy": "2021-08-16T22:55:10.591978Z",
     "iopub.status.idle": "2021-08-16T22:55:14.91458Z",
     "shell.execute_reply": "2021-08-16T22:55:14.912747Z",
     "shell.execute_reply.started": "2021-08-16T22:55:10.592407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.527335</td>\n",
       "      <td>0.230599</td>\n",
       "      <td>-0.118039</td>\n",
       "      <td>0.405965</td>\n",
       "      <td>0.497053</td>\n",
       "      <td>0.668060</td>\n",
       "      <td>1.058443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.460926</td>\n",
       "      <td>0.214003</td>\n",
       "      <td>-0.069309</td>\n",
       "      <td>0.310494</td>\n",
       "      <td>0.427903</td>\n",
       "      <td>0.615113</td>\n",
       "      <td>0.887253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.490498</td>\n",
       "      <td>0.253346</td>\n",
       "      <td>-0.056104</td>\n",
       "      <td>0.300604</td>\n",
       "      <td>0.502462</td>\n",
       "      <td>0.647512</td>\n",
       "      <td>1.034704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>0.219199</td>\n",
       "      <td>0.130676</td>\n",
       "      <td>0.329783</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.664451</td>\n",
       "      <td>1.039560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.491654</td>\n",
       "      <td>0.240074</td>\n",
       "      <td>0.255908</td>\n",
       "      <td>0.284188</td>\n",
       "      <td>0.390470</td>\n",
       "      <td>0.696599</td>\n",
       "      <td>1.055424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.510526</td>\n",
       "      <td>0.228232</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>0.354141</td>\n",
       "      <td>0.488865</td>\n",
       "      <td>0.669625</td>\n",
       "      <td>1.067649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.467476</td>\n",
       "      <td>0.210331</td>\n",
       "      <td>-0.224689</td>\n",
       "      <td>0.342873</td>\n",
       "      <td>0.429383</td>\n",
       "      <td>0.573383</td>\n",
       "      <td>1.111552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.537119</td>\n",
       "      <td>0.218140</td>\n",
       "      <td>0.203763</td>\n",
       "      <td>0.355825</td>\n",
       "      <td>0.504661</td>\n",
       "      <td>0.703441</td>\n",
       "      <td>1.032837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.498456</td>\n",
       "      <td>0.239920</td>\n",
       "      <td>-0.260275</td>\n",
       "      <td>0.332486</td>\n",
       "      <td>0.439151</td>\n",
       "      <td>0.606056</td>\n",
       "      <td>1.040229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.474872</td>\n",
       "      <td>0.218007</td>\n",
       "      <td>0.117896</td>\n",
       "      <td>0.306874</td>\n",
       "      <td>0.434620</td>\n",
       "      <td>0.614333</td>\n",
       "      <td>0.982922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.474492</td>\n",
       "      <td>0.255949</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>0.276017</td>\n",
       "      <td>0.459975</td>\n",
       "      <td>0.691579</td>\n",
       "      <td>1.055960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.473216</td>\n",
       "      <td>0.222022</td>\n",
       "      <td>0.052608</td>\n",
       "      <td>0.308151</td>\n",
       "      <td>0.433812</td>\n",
       "      <td>0.642057</td>\n",
       "      <td>1.071444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.494561</td>\n",
       "      <td>0.247292</td>\n",
       "      <td>-0.074208</td>\n",
       "      <td>0.289074</td>\n",
       "      <td>0.422887</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>0.975035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.508273</td>\n",
       "      <td>0.222950</td>\n",
       "      <td>0.151050</td>\n",
       "      <td>0.300669</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.758447</td>\n",
       "      <td>0.905992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>300000.0</td>\n",
       "      <td>8.241979</td>\n",
       "      <td>0.746555</td>\n",
       "      <td>0.140329</td>\n",
       "      <td>7.742071</td>\n",
       "      <td>8.191373</td>\n",
       "      <td>8.728634</td>\n",
       "      <td>10.411992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std       min       25%       50%       75%  \\\n",
       "cont0   300000.0  0.527335  0.230599 -0.118039  0.405965  0.497053  0.668060   \n",
       "cont1   300000.0  0.460926  0.214003 -0.069309  0.310494  0.427903  0.615113   \n",
       "cont2   300000.0  0.490498  0.253346 -0.056104  0.300604  0.502462  0.647512   \n",
       "cont3   300000.0  0.496689  0.219199  0.130676  0.329783  0.465026  0.664451   \n",
       "cont4   300000.0  0.491654  0.240074  0.255908  0.284188  0.390470  0.696599   \n",
       "cont5   300000.0  0.510526  0.228232  0.045915  0.354141  0.488865  0.669625   \n",
       "cont6   300000.0  0.467476  0.210331 -0.224689  0.342873  0.429383  0.573383   \n",
       "cont7   300000.0  0.537119  0.218140  0.203763  0.355825  0.504661  0.703441   \n",
       "cont8   300000.0  0.498456  0.239920 -0.260275  0.332486  0.439151  0.606056   \n",
       "cont9   300000.0  0.474872  0.218007  0.117896  0.306874  0.434620  0.614333   \n",
       "cont10  300000.0  0.474492  0.255949  0.048732  0.276017  0.459975  0.691579   \n",
       "cont11  300000.0  0.473216  0.222022  0.052608  0.308151  0.433812  0.642057   \n",
       "cont12  300000.0  0.494561  0.247292 -0.074208  0.289074  0.422887  0.714502   \n",
       "cont13  300000.0  0.508273  0.222950  0.151050  0.300669  0.472400  0.758447   \n",
       "target  300000.0  8.241979  0.746555  0.140329  7.742071  8.191373  8.728634   \n",
       "\n",
       "              max  \n",
       "cont0    1.058443  \n",
       "cont1    0.887253  \n",
       "cont2    1.034704  \n",
       "cont3    1.039560  \n",
       "cont4    1.055424  \n",
       "cont5    1.067649  \n",
       "cont6    1.111552  \n",
       "cont7    1.032837  \n",
       "cont8    1.040229  \n",
       "cont9    0.982922  \n",
       "cont10   1.055960  \n",
       "cont11   1.071444  \n",
       "cont12   0.975035  \n",
       "cont13   0.905992  \n",
       "target  10.411992  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "\n",
    "# Preview the data\n",
    "train.head()\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell separates the target (which we assign to `y`) from the training features (which we assign to `features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:14.916952Z",
     "iopub.status.busy": "2021-08-16T22:55:14.916515Z",
     "iopub.status.idle": "2021-08-16T22:55:14.984676Z",
     "shell.execute_reply": "2021-08-16T22:55:14.98316Z",
     "shell.execute_reply.started": "2021-08-16T22:55:14.916916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat0</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat1</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat2</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat3</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat4</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat5</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat6</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat7</th>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat8</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat9</th>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont0</th>\n",
       "      <td>0.20147</td>\n",
       "      <td>0.743068</td>\n",
       "      <td>0.742708</td>\n",
       "      <td>0.429551</td>\n",
       "      <td>1.05829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont1</th>\n",
       "      <td>-0.0148218</td>\n",
       "      <td>0.367411</td>\n",
       "      <td>0.310383</td>\n",
       "      <td>0.620998</td>\n",
       "      <td>0.367492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont2</th>\n",
       "      <td>0.669699</td>\n",
       "      <td>1.02161</td>\n",
       "      <td>-0.0126728</td>\n",
       "      <td>0.577942</td>\n",
       "      <td>-0.0523886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont3</th>\n",
       "      <td>0.136278</td>\n",
       "      <td>0.365798</td>\n",
       "      <td>0.576957</td>\n",
       "      <td>0.28061</td>\n",
       "      <td>0.232407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont4</th>\n",
       "      <td>0.610706</td>\n",
       "      <td>0.276853</td>\n",
       "      <td>0.285074</td>\n",
       "      <td>0.284667</td>\n",
       "      <td>0.287595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont5</th>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.533087</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.66898</td>\n",
       "      <td>0.686964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont6</th>\n",
       "      <td>0.160266</td>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.420667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont7</th>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.732948</td>\n",
       "      <td>0.648182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont8</th>\n",
       "      <td>0.38947</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.679618</td>\n",
       "      <td>0.684501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont9</th>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.956692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont10</th>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.34601</td>\n",
       "      <td>1.00077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont11</th>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.71461</td>\n",
       "      <td>0.776742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont12</th>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.54015</td>\n",
       "      <td>0.625849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont13</th>\n",
       "      <td>0.86985</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>0.763846</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>0.250823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id              1         2          3         4          6\n",
       "cat0            B         B          A         B          A\n",
       "cat1            B         B          A         B          A\n",
       "cat2            B         A          A         A          A\n",
       "cat3            C         A          C         C          C\n",
       "cat4            B         B          B         B          B\n",
       "cat5            B         D          D         D          D\n",
       "cat6            A         A          A         A          A\n",
       "cat7            E         F          D         E          E\n",
       "cat8            C         A          A         C          A\n",
       "cat9            N         O          F         K          N\n",
       "cont0     0.20147  0.743068   0.742708  0.429551    1.05829\n",
       "cont1  -0.0148218  0.367411   0.310383  0.620998   0.367492\n",
       "cont2    0.669699   1.02161 -0.0126728  0.577942 -0.0523886\n",
       "cont3    0.136278  0.365798   0.576957   0.28061   0.232407\n",
       "cont4    0.610706  0.276853   0.285074  0.284667   0.287595\n",
       "cont5    0.400361  0.533087   0.650609   0.66898   0.686964\n",
       "cont6    0.160266  0.558922   0.375348  0.239061   0.420667\n",
       "cont7    0.310921  0.516294   0.902567  0.732948   0.648182\n",
       "cont8     0.38947  0.594928   0.555205  0.679618   0.684501\n",
       "cont9    0.267559  0.341439   0.843531  0.574844   0.956692\n",
       "cont10   0.237281  0.906013   0.748809   0.34601    1.00077\n",
       "cont11   0.377873  0.921701   0.620126   0.71461   0.776742\n",
       "cont12   0.322401  0.261975   0.541474   0.54015   0.625849\n",
       "cont13    0.86985  0.465083   0.763846  0.280682   0.250823"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate target from features\n",
    "y = train['target']\n",
    "features = train.drop(['target'], axis=1)\n",
    "\n",
    "# Preview features\n",
    "features.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = features.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = features.select_dtypes(include=['object', 'bool']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-16T22:55:17.707975Z",
     "iopub.status.busy": "2021-08-16T22:55:17.7076Z",
     "iopub.status.idle": "2021-08-16T22:55:19.670568Z",
     "shell.execute_reply": "2021-08-16T22:55:19.669219Z",
     "shell.execute_reply.started": "2021-08-16T22:55:17.707941Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = features.copy()\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f02dc7aa483d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we will use indexes for the transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnumerical_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcategorical_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# we will use indexes for the transformers \n",
    "numerical_ix = X.columns.get_indexer(numerical_cols)\n",
    "categorical_ix = X.columns.get_indexer(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "These are two functions to save and load predictions, they can be wrapped within a class for a better modeling or kept as they are since they are independent of the project setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## helper fucntions\n",
    "def store_oof_predictions(model_name,\n",
    "                          valid_predictions,\n",
    "                          test_predictions,\n",
    "                          X_train,\n",
    "                          X_test,\n",
    "                          stacking_level,\n",
    "                          output_folder,\n",
    "                          n_folds, \n",
    "                          random_state):    \n",
    "    \n",
    "    \"\"\"\n",
    "    Store oof predictions into files.\n",
    "    It is safe not to use defaults for this helper to make sure \n",
    "    we are storing the right experiement. \n",
    "    \"\"\"\n",
    "    \n",
    "    if test_predictions is not None:\n",
    "        test_df = pd.DataFrame({'Id': X_test.index,\n",
    "                       model_name: test_predictions})\n",
    "        test_df.to_csv( f'{output_folder}{os.sep}{model_name}_{n_folds}_test.csv',\n",
    "                       index=False)\n",
    "\n",
    "    if valid_predictions is not None:\n",
    "        valid_df = pd.DataFrame({'Id': X_train.index,\n",
    "                           model_name: valid_predictions})\n",
    "        valid_df.to_csv(f'{output_folder}{os.sep}{model_name}_{n_folds}_valid.csv', \n",
    "                        index=False)\n",
    "    \n",
    "    \n",
    "def read_oof_predictions(pattern, \n",
    "                     models_names, \n",
    "                     index='id'):    \n",
    "    \"\"\"\n",
    "    Read files according the pattern in their name\n",
    "    it returns a dataframe where each column is the prediction of a model\n",
    "    \"\"\"\n",
    "    li = [] \n",
    "    for f in glob.glob(pattern):\n",
    "        file_name = f.split(os.sep)[-1] # get file name only\n",
    "        if file_name.lower().startswith(tuple(s.lower() for s in models_names)): # get only required models\n",
    "            df = pd.read_csv(f, index_col=0)\n",
    "            li.append(df)\n",
    "    \n",
    "                                   \n",
    "    return pd.concat(li, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment \n",
    "Since everything boiled down to stacking (even if we have a single level), the experiment class will handle the organization of the resulted files from the test: test and oofs predictions. Therefore, assuming the project has the following structure with a folder called **experiments** we can save our tests in this folder. This is what this class will do. Another important thing is to create the CV folds, and use them. Currently the class supports one seed only, but that can be changed easily by creating a list of CV indexes instead of a single one. I will add that in the next round.\n",
    "\n",
    "```\n",
    "    ML30_project\n",
    "    │   README.md\n",
    "    │\n",
    "    └───notebooks\n",
    "    │   ...\n",
    "    │\n",
    "    └───experiments\n",
    "    │   │   \n",
    "    │   │\n",
    "    │   └───experiment_1\n",
    "    │   │   │   \n",
    "    │   │   └───level_1\n",
    "    │   │   │   xgb_test.csv\n",
    "    │   │   │   xgb_test.csv\n",
    "    │   │   │   ...\n",
    "    │   │   └───level_2\n",
    "    │   │   │   ...\n",
    "    │   │   └───level_3\n",
    "    │   │   │   ...\n",
    "    │   │   └───level_...\n",
    "    │   │\n",
    "    │   │\n",
    "    │   └───experiment_...\n",
    "```\n",
    "\n",
    "\n",
    ">The code that generated the results is important to save too, but that can be done easily by creating a new version of the notebook or copying notebook with the CV_LB results.\n",
    "\n",
    ">This class is so important when running notebooks in our computers since Kaggle has a nice notebook management system which saves outputs as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-96f662cc85f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def __init__(self,\n\u001b[1;32m      3\u001b[0m                  \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Experiment'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-96f662cc85f1>\u001b[0m in \u001b[0;36mExperiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                  \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  \u001b[0muse_different_random_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                  main_folder=os.getcwd()):\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class Experiment():\n",
    "    def __init__(self,\n",
    "                 title='Experiment',\n",
    "                 n_folds=3,\n",
    "                 random_state=42,\n",
    "                 shuffle=True,\n",
    "                 use_different_random_states=True,\n",
    "                 main_folder=os.getcwd()):\n",
    "        \n",
    "        self.title = title\n",
    "        self.n_folds = n_folds\n",
    "        self.random_state = random_state\n",
    "        self.shuffle = shuffle\n",
    "        self.use_different_random_states = use_different_random_states\n",
    "        self.main_folder = main_folder\n",
    "        \n",
    "        \n",
    "    def calc_folds_indexes(self, X, y, sampler=KFold):\n",
    "        \"\"\"\n",
    "        sampler: can be KFold,  StratifiedKFold, or any sampling class  \n",
    "        \"\"\"\n",
    "        \n",
    "        folds = sampler(n_splits=self.n_folds, \n",
    "                        random_state=self.random_state,\n",
    "                        shuffle=self.shuffle)\n",
    "        self.folds_idxs = list(self.folds.split(X, y))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def join_folder(self, folder=None):\n",
    "            \n",
    "        # create time stamp and subfolder with the current time stamp\n",
    "        if folder is not None: # if folder is specified\n",
    "            self.output_folder = folder \n",
    "        else: # create a folder with the time stamp\n",
    "            time_stamp = datetime.now().isoformat(' ', 'seconds')\n",
    "            self.output_folder = self.title + ' ' + time_stamp.replace(':', '-')\n",
    "            Path(f'{self.main_folder}{os.sep}{self.output_folder}').mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "     \n",
    "    def to_dict(self):\n",
    "        return dict({\"title\": self.title,\n",
    "                    \"n_folds\": self.n_folds,\n",
    "                    \"random_state\": self.random_state,\n",
    "                    \"use_different_random_states\": self.use_different_random_states,\n",
    "                    \"main_folder\": self.main_folder,\n",
    "                    \"output_folder\": self.output_folder})\n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        return str(self.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelWrapper \n",
    "This class role is to avoid coding multiple classes for each model (or model types). We can see that models can actually be categorized into different categories, where some models accept more parameters than the others. For instance xgboost can use an evaluation set to determine the stopping round number, while Lasso does not accept such extra parameters.\n",
    "\n",
    "Thanks to the flexibility of python and the design of the base models, we can wrap the model and `wrapper` to do what the model should do. In fact, we can easily stretch this class to support sklearn pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper():\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 name,\n",
    "                 uses_eval_set=False,\n",
    "                 fit_params={}):\n",
    "        \n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        \n",
    "        self.uses_eval_set = uses_eval_set\n",
    "        self.fit_params = fit_params # any extra params for the 'fit' function\n",
    "                \n",
    "    def fit(self, X, y, eval_set=None):\n",
    "        if self.uses_eval_set:\n",
    "            self.model.fit(X, y, eval_set=eval_set, **(self.fit_params))\n",
    "        else:\n",
    "            self.model.fit(X, y, **(self.fit_params)) \n",
    "        return self\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "    def clone_me(self, random_state=None):\n",
    "        wrapper = ModelWrapper(model=clone(self.model), # clone from sklean.base\n",
    "                               name=self.name, \n",
    "                               uses_eval_set=self.uses_eval_set,\n",
    "                               fit_params=self.fit_params)\n",
    "        wrapper.name = self.name\n",
    "        if random_state is not None:\n",
    "            wrapper.set_random_state(random_state)\n",
    "        \n",
    "        return wrapper\n",
    "    \n",
    "    def set_random_state(self, random_state):\n",
    "        if hasattr(self.model, 'random_state'):\n",
    "            self.model.random_state = random_state\n",
    "        elif hasattr(self.model, 'random_seed'):\n",
    "            self.model.random_seed = random_state\n",
    "            \n",
    "    def get_random_state(self):\n",
    "        if hasattr(self.model, 'random_state'):\n",
    "            return self.model.random_state \n",
    "        elif hasattr(self.model, 'random_seed'):\n",
    "            return self.model.random_seed\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelTrainer\n",
    "This class role is to the a model and calculate the oofs and the test results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ModelWrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-34d37a310f85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def __init__(self,\n\u001b[1;32m      3\u001b[0m                   model: ModelWrapper):\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-34d37a310f85>\u001b[0m in \u001b[0;36mModelTrainer\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     def __init__(self,\n\u001b[0;32m----> 3\u001b[0;31m                   model: ModelWrapper):\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ModelWrapper' is not defined"
     ]
    }
   ],
   "source": [
    "class ModelTrainer():\n",
    "    def __init__(self,\n",
    "                  model: ModelWrapper):\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "    def calc_oofs(self,\n",
    "                  X, y,\n",
    "                  X_test,\n",
    "                  folds,\n",
    "                  transformer=None,\n",
    "                  verbose=False,\n",
    "                  use_different_random_states=True):\n",
    "        \"\"\"\n",
    "        Return the oofs predictions and the meta features (test predictions)\n",
    "        \"\"\"\n",
    "        \n",
    "        test_predictions = 0\n",
    "        oof_predictions = np.zeros_like(np.array(y))\n",
    "        valid_mean_score = [] \n",
    "                \n",
    "        for fold, (train_ix, valid_ix) in enumerate(folds.split(X, y)):\n",
    "            X_train, X_valid = X[train_ix], X[valid_ix]\n",
    "            y_train, y_valid = y[train_ix], y[valid_ix]\n",
    "                        \n",
    "            \n",
    "            # transform input\n",
    "            if transformer is not None:\n",
    "                X_train = transformer.fit_transform(X_train)\n",
    "                X_valid = transformer.transform(X_valid)\n",
    "\n",
    "            \n",
    "            # check if we train each fold on differently initialized clone\n",
    "            if use_different_random_states:\n",
    "                model = self.model.clone_me(random_state=fold)\n",
    "            else:\n",
    "                model = self.model.clone_me()\n",
    "            \n",
    "            # fit the model\n",
    "            if model.uses_eval_set:\n",
    "                model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)])\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "            ## predictions\n",
    "            # on the validation set\n",
    "            valid_predications = model.predict(X_valid)\n",
    "            score = mean_squared_error(valid_predications, y_valid, squared=False)\n",
    "            valid_mean_score.append(score)\n",
    "            oof_predictions[valid_ix] = valid_predications\n",
    "            \n",
    "            # on the test set\n",
    "            # transform it first on a copy\n",
    "            if transformer is not None:\n",
    "                X_test_ = transformer.transform(X_test)\n",
    "            else:\n",
    "                X_test_ = X_test\n",
    "            test_predictions += model.predict(X_test_) / folds.n_splits\n",
    "            \n",
    "            if verbose:\n",
    "                print('Fold:{} score:{:.4f}'.format(fold + 1, score))\n",
    "        \n",
    "        if verbose:\n",
    "            print('Average score:{:.4f} ({:.4f})'.format(np.mean(valid_mean_score), np.std(valid_mean_score) ))\n",
    "    \n",
    "        return oof_predictions, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LevelTrainer\n",
    "This class role glues, everything in one place and train each model in a given level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LevelTrainer():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 experiment, # Experiment,\n",
    "                 models,      # ModelWrapper\n",
    "                 transformer, # data transformer\n",
    "                 level_num=1):\n",
    "        \n",
    "        self.level_num = level_num\n",
    "        self.experiment = experiment\n",
    "        self.models = models\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def train(self, X_df, y_df, X_test_df, verbose=True):\n",
    "        \n",
    "        assert models is not None\n",
    "        \n",
    "\n",
    "        for model_wrapper in self.models:\n",
    "            \n",
    "            if verbose:\n",
    "                print('-'*30)\n",
    "                print(f'Model:{model_wrapper.name}')\n",
    "                print('-'*30)\n",
    "                \n",
    "            trainer = ModelTrainer(model_wrapper)\n",
    "            oof_preds, test_preds = trainer.calc_oofs(X_df.values, y_df.values,\n",
    "                                                      X_test_df.values,\n",
    "                                                      transformer=self.transformer,\n",
    "                                                      folds=self.experiment.folds,\n",
    "                                                      verbose=verbose,\n",
    "                                                      use_different_random_states=self.experiment.use_different_random_states)\n",
    "            # store predictions\n",
    "            store_oof_predictions(model_name=model_wrapper.name,\n",
    "                                  valid_predictions=oof_preds,\n",
    "                                  test_predictions=test_preds,\n",
    "                                  X_train=X_df,\n",
    "                                  X_test=X_test_df,\n",
    "                                  stacking_level=self.level_num, \n",
    "                                  n_folds=self.experiment.n_folds, \n",
    "                                  random_state=model_wrapper.get_random_state(),\n",
    "                                  output_folder=f'{self.experiment.main_folder}{os.sep}{self.experiment.output_folder}')\n",
    "            if verbose:\n",
    "                print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Here goes the paramaters of each model. These can actually be stored in an external JSON file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-61c9ff2fb440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Lasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m lasso_params = {\n\u001b[0;32m----> 3\u001b[0;31m                 \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.00005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "lasso_params = {\n",
    "                alpha: 0.00005\n",
    "}\n",
    "\n",
    "\n",
    "# Elastic Net\n",
    "enet_params = {\n",
    "               alpha: 0.00005, \n",
    "               l1_ratio: .9\n",
    "}\n",
    "\n",
    "# extra-tree\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "# random forest\n",
    "\n",
    "rf_params_2 = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 5\n",
    "}\n",
    "\n",
    "\n",
    "rf_params_1 = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2\n",
    "}\n",
    "\n",
    "# gradient boosting \n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     'max_depth': 3\n",
    "}\n",
    "\n",
    "# xgboost\n",
    "\n",
    "# Using optuna but still rough\n",
    "xgb_params_2 = {\n",
    "#                  'tree_method': 'gpu_hist', \n",
    "#                  'gpu_id': 0, \n",
    "#                  'predictor': 'gpu_predictor',\n",
    "    \n",
    "                 'max_depth': 5,\n",
    "                 'learning_rate': 0.021252439960137114,\n",
    "                 'n_estimators': 13500,\n",
    "                 'subsample': 0.62,\n",
    "                 'booster': 'gbtree',\n",
    "                 'colsample_bytree': 0.1,\n",
    "                 'reg_lambda': 0.1584605320779582,\n",
    "                 'reg_alpha': 15.715145781076245,\n",
    "                 'n_jobs': -1\n",
    "}\n",
    "\n",
    "xgb_params_1 = {\n",
    "            'random_state': 1, \n",
    "            # gpu\n",
    "    #         'tree_method': 'gpu_hist', \n",
    "    #         'gpu_id': 0, \n",
    "    #         'predictor': 'gpu_predictor',\n",
    "            # cpu\n",
    "            'n_jobs': -1,\n",
    "            'booster': 'gbtree',\n",
    "            'n_estimators': 10000,\n",
    "            # optimized params\n",
    "            'learning_rate': 0.03628302216953097,\n",
    "            'reg_lambda': 0.0008746338866473539,\n",
    "            'reg_alpha': 23.13181079976304,\n",
    "            'subsample': 0.7875490025178415,\n",
    "            'colsample_bytree': 0.11807135201147481,\n",
    "            'max_depth': 3,\n",
    "            #'min_child_weight': 6\n",
    "}\n",
    "\n",
    "\n",
    "# catboost\n",
    "catb_params_2 = {'iterations': 20000,\n",
    "              'learning_rate': 0.45,\n",
    "              'loss_function': \"RMSE\",\n",
    "              'random_state': 0,\n",
    "              'verbose': 0,\n",
    "              'thread_count': -1,\n",
    "              'depth': 1}\n",
    "\n",
    "\n",
    "catb_params_1 = {'iterations': 6800,\n",
    "              'learning_rate': 0.93,\n",
    "              'loss_function': \"RMSE\",\n",
    "              'random_state': 42,\n",
    "              'verbose': 0,\n",
    "              'thread_count': -1,\n",
    "              'depth': 1,\n",
    "              'l2_leaf_reg': 3.28}\n",
    "\n",
    "\n",
    "# using optuna\n",
    "params_lgb = {\n",
    "             \"n_estimators\": 10000,\n",
    "             'metric':'rmse',\n",
    "             \"objective\": \"regression\",\n",
    "             'max_depth': 12, \n",
    "             'subsample': 0.587082286344555, \n",
    "             'colsample_bytree': 0.2157299997089329, \n",
    "             'learning_rate': 0.01270518267668901,\n",
    "             'reg_lambda': 36.78473508062132,\n",
    "             'reg_alpha': 14.155146595119032, \n",
    "             'min_child_samples': 6, \n",
    "             'num_leaves': 34, \n",
    "             'max_bin': 914,\n",
    "             'cat_smooth': 26,\n",
    "             'n_jobs': -1,\n",
    "             'cat_l2': 0.020257336654989123\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are model/task dependent parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external hyperparamaters\n",
    "\n",
    "### fit function hyperparamaters\n",
    "# some models require special paramaters like early stoping in xgboost and lgbm\n",
    "fit_params = {'early_stopping_rounds': 300,\n",
    "                  'verbose': False}\n",
    "\n",
    "### application/implementation paramaters\n",
    "# These paramaters are implementation dependent \n",
    "app_params = {'uses_eval_set':True}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "Here we define goes all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg = LinearRegression()\n",
    "# lasso\n",
    "lasso = Lasso(**lasso_params)\n",
    "\n",
    "# Elastic net\n",
    "e_net = ElasticNet(**enet_params)\n",
    "\n",
    "# KNeighborsRegressor\n",
    "knn =  KNeighborsRegressor()\n",
    "\n",
    "# extra-tree\n",
    "extree = ExtraTreesRegressor(**et_params)\n",
    "\n",
    "# random forest\n",
    "rfr = RandomForestRegressor(**rf_params_2)\n",
    "\n",
    "# gradient boosting\n",
    "gb = GradientBoostingRegressor(**gb_params)\n",
    "\n",
    "#lgbm\n",
    "lgb = LGBMRegressor(**params_lgb_1)\n",
    "\n",
    "# variants\n",
    "\n",
    "# xgboost\n",
    "xgb_1 =  XGBRegressor(**xgb_params_1)\n",
    "xgb_2 =  XGBRegressor(**xgb_params_2)\n",
    "\n",
    "#catboost\n",
    "catb_1 = CatBoostRegressor(**catb_params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all settings in one dictionary, \n",
    "# we can store/load it then to a JSON file\n",
    "models = {'LinearRegression': {\"model\":lrg, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'Lasso': {\"model\":lasso, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'ElasticNet': {\"model\": e_net, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'ExtraTreesRegressor': {\"model\": extree, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'RandomForestRegressor': {\"model\": rfr, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'GradientBoostingRegressor': {\"model\": gb, \"fit_kwargs\":None, \"app_params\": None},\n",
    "          'XGBRegressor-1': {\"model\": xgb_1, \"fit_kwargs\":fit_params_300, \"app_params\": app_params},\n",
    "          'XGBRegressor-2': {\"model\": xgb_2, \"fit_kwargs\":fit_params_300, \"app_params\": app_params},\n",
    "          'CatBoostRegressor-1': {\"model\": catb_1, \"fit_kwargs\": fit_params_300, \"app_params\": fit_params_300},\n",
    "          'LGBMRegressor': {\"model\": lgb, \"fit_kwargs\":fit_params_300, \"app_params\": app_params}\n",
    "          # we can add any number of models here \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LinearRegression', 'Lasso', 'ElasticNet', 'ExtraTreesRegressor', 'RandomForestRegressor', 'GradientBoostingRegressor', 'XGBRegressor-1', 'XGBRegressor-2', 'XGBRegressor-3', 'XGBRegressor-4', 'XGBRegressor-5', 'CatBoostRegressor-1', 'CatBoostRegressor-2', 'CatBoostRegressor-3', 'LGBMRegressor'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "Here goes the actual stacking procedure. \n",
    "   - We first define the architecture, and setup the a session.\n",
    "   - Define the stack. That is, the models and transformers in the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings: experiment and stacking architecutre\n",
    "session_folder = \"Experiments/new_session\"\n",
    "X_train_, X_test_ = X_train, X_test # initialized to the input\n",
    "\n",
    "\n",
    "# any special transformers for any level\n",
    "level_1_transformers = [('cat', OrdinalEncoder(), categorical_ix), ('num', MinMaxScaler(), numerical_ix)]\n",
    "level_1_col_transform = ColumnTransformer(transformers=level_1_transformers)\n",
    "\n",
    "\n",
    "level_2_transform = None # MinMaxScaler() PowerTransformer() \n",
    "\n",
    "stack = [ {\"level-id\": \"level-1\", \n",
    "           \"models\": [\n",
    "                     'CatBoostRegressor-1',\n",
    "                     'XGBRegressor-1',\n",
    "                     # we can add any model here\n",
    "                    ],\n",
    "            \"use-only\": None, # to select subset of models in the next level\n",
    "            \"n_folds\": 5,\n",
    "            \"folder\": \"level_1\", \n",
    "            \"transformer\": level_1_col_transform, \n",
    "            \"frozen\": False\n",
    "            },\n",
    "               \n",
    "           {\"level-id\": \"level-2\",\n",
    "            \"models\": [\n",
    "                       'RandomForestRegressor'\n",
    "                      ],\n",
    "            \"use-only\": None, \n",
    "            \"n_folds\": 5,\n",
    "            \"folder\": \"level_2\",\n",
    "            \"transformer\": level_2_transform,\n",
    "            \"frozen\": False\n",
    "          },\n",
    "\n",
    "# we can add any number of levels here\n",
    "#           {\"level-id\": \"level-3\",\n",
    "#             \"models\": ['Lasso',\n",
    "#                        'XGBRegressor-1', \n",
    "#                        'CatBoostRegressor-1',\n",
    "#                        'LGBMRegressor',\n",
    "#                        'RandomForestRegressor'],\n",
    "#             \"use-only\": None, \n",
    "#             \"n_folds\": 5,\n",
    "#             \"folder\": \"level_3\",\n",
    "#             \"transformer\": level_2_transform \n",
    "#           }\n",
    "        \n",
    "        ]\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loop through each level in the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Current Level: level-1\n",
      "--------------------------------------------------\n",
      "This level is already trained\n",
      "Experiments/new_session/level_1/*5_valid.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBRegressor-1</th>\n",
       "      <th>CatBoostRegressor-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.484386</td>\n",
       "      <td>8.477987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.435083</td>\n",
       "      <td>8.315481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.215256</td>\n",
       "      <td>8.254283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.350307</td>\n",
       "      <td>8.387012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.248346</td>\n",
       "      <td>8.270340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.078706</td>\n",
       "      <td>8.038880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.282299</td>\n",
       "      <td>8.271361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.346571</td>\n",
       "      <td>8.356183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.389336</td>\n",
       "      <td>8.405265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.109003</td>\n",
       "      <td>8.036126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGBRegressor-1  CatBoostRegressor-1\n",
       "Id                                     \n",
       "1         8.484386             8.477987\n",
       "2         8.435083             8.315481\n",
       "3         8.215256             8.254283\n",
       "4         8.350307             8.387012\n",
       "6         8.248346             8.270340\n",
       "7         8.078706             8.038880\n",
       "8         8.282299             8.271361\n",
       "9         8.346571             8.356183\n",
       "10        8.389336             8.405265\n",
       "11        8.109003             8.036126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBRegressor-1</th>\n",
       "      <th>CatBoostRegressor-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.079207</td>\n",
       "      <td>8.089023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.393541</td>\n",
       "      <td>8.409556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.415014</td>\n",
       "      <td>8.434104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.500801</td>\n",
       "      <td>8.562139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.134493</td>\n",
       "      <td>8.154888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.306716</td>\n",
       "      <td>8.282289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.542321</td>\n",
       "      <td>8.476730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.881266</td>\n",
       "      <td>7.846250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.073944</td>\n",
       "      <td>8.140942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.311528</td>\n",
       "      <td>8.346391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGBRegressor-1  CatBoostRegressor-1\n",
       "Id                                     \n",
       "0         8.079207             8.089023\n",
       "5         8.393541             8.409556\n",
       "15        8.415014             8.434104\n",
       "16        8.500801             8.562139\n",
       "17        8.134493             8.154888\n",
       "19        8.306716             8.282289\n",
       "20        8.542321             8.476730\n",
       "21        7.881266             7.846250\n",
       "23        8.073944             8.140942\n",
       "29        8.311528             8.346391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if we need to freeze a level\n",
    "# I think we can also add a feature easily to freeze a model at a level\n",
    "\n",
    "# run the stack\n",
    "for  level in stack:\n",
    "    \n",
    "    print('-'*50)\n",
    "    print(f'Current Level: {level[\"level-id\"]}')\n",
    "    print('-'*50)\n",
    "    \n",
    "    # get current path\n",
    "    output_path = os.getcwd()\n",
    "    \n",
    "    # get models \n",
    "    # if level_1_models is set to 'all' use all models\n",
    "    if level['models'][0].lower() == 'all':\n",
    "        level_models_names = models.keys()\n",
    "    else: \n",
    "        level_models_names = level['models']\n",
    "\n",
    "    # create experiment\n",
    "    ml30_experiment = Experiment(title='ML 30 days',\n",
    "                        n_folds=level['n_folds'],\n",
    "                        random_state=42,\n",
    "                        shuffle=True,\n",
    "                        use_different_random_states=True,\n",
    "                        main_folder=f'{output_path}{os.sep}{session_folder}')\n",
    "\n",
    "    ml30_experiment.create(use_folder=level['folder'], resume=True)\n",
    "\n",
    "    # create models\n",
    "    model_wrappers = []\n",
    "    for model_name in level_models_names:\n",
    "\n",
    "        # get paramaters  \n",
    "        model = models[model_name]\n",
    "        fit_kwargs = models[model_name]['fit_kwargs']\n",
    "        app_params = models[model_name]['app_params']\n",
    "\n",
    "        model_wrapper = ModelWrapper(model=model['model'], name=model_name)\n",
    "        if fit_kwargs is not None:\n",
    "            model_wrapper.fit_params = fit_kwargs\n",
    "        if app_params is not None:\n",
    "            model_wrapper.uses_eval_set = app_params['uses_eval_set']\n",
    "        model_wrappers.append(model_wrapper)\n",
    "\n",
    "        \n",
    "    # train the level\n",
    "    if freeze is not None:\n",
    "        if level['level-id'] not in freeze:  # escape any trained level   \n",
    "            level_trainer = LevelTrainer(experiment=ml30_experiment, \n",
    "                                 models=model_wrappers, \n",
    "                                 transformer=level['transformer'])\n",
    "\n",
    "            level_trainer.train(X_df=X_train_, y_df=y, X_test_df=X_test_)\n",
    "        else:\n",
    "            print('This level is already trained')\n",
    "            \n",
    "\n",
    "    # collect results    \n",
    "    fold_id = ml30_experiment.n_folds\n",
    "    folder =f'{session_folder}{os.sep}{ml30_experiment.output_folder}'\n",
    "                            \n",
    "    print(f\"{folder}{os.sep}*{fold_id}_valid.csv\")\n",
    "    \n",
    "    # new features \n",
    "    X_train_ = read_oof_predictions(pattern=f\"{folder}{os.sep}*{fold_id}_valid.csv\",\n",
    "                               models_names=level_models_names)\n",
    "    X_test_ = read_oof_predictions(pattern=f\"{folder}{os.sep}*{fold_id}_test.csv\",\n",
    "                              models_names=level_models_names)\n",
    "    \n",
    "    display(X_train_.head(10))\n",
    "    display(X_test_.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBRegressor-1</th>\n",
       "      <th>CatBoostRegressor-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.079207</td>\n",
       "      <td>8.089023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.393541</td>\n",
       "      <td>8.409556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.415014</td>\n",
       "      <td>8.434104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.500801</td>\n",
       "      <td>8.562139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.134493</td>\n",
       "      <td>8.154888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.306716</td>\n",
       "      <td>8.282289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.542321</td>\n",
       "      <td>8.476730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.881266</td>\n",
       "      <td>7.846250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.073944</td>\n",
       "      <td>8.140942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.311528</td>\n",
       "      <td>8.346391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGBRegressor-1  CatBoostRegressor-1\n",
       "Id                                     \n",
       "0         8.079207             8.089023\n",
       "5         8.393541             8.409556\n",
       "15        8.415014             8.434104\n",
       "16        8.500801             8.562139\n",
       "17        8.134493             8.154888\n",
       "19        8.306716             8.282289\n",
       "20        8.542321             8.476730\n",
       "21        7.881266             7.846250\n",
       "23        8.073944             8.140942\n",
       "29        8.311528             8.346391"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final results\n",
    "X_test_.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-16T22:54:17.068352Z",
     "iopub.status.idle": "2021-08-16T22:54:17.068911Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = X_test_.values\n",
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'target': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.072493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8.420695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>8.421442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>8.501886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>8.157393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>8.329672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>8.523518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>7.858731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>8.060452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>8.331367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31</td>\n",
       "      <td>8.381876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>7.776227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33</td>\n",
       "      <td>8.421997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34</td>\n",
       "      <td>8.205416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35</td>\n",
       "      <td>8.477636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37</td>\n",
       "      <td>8.428248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>8.161027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>39</td>\n",
       "      <td>8.396740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40</td>\n",
       "      <td>8.475544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44</td>\n",
       "      <td>7.963849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id    target\n",
       "0    0  8.072493\n",
       "1    5  8.420695\n",
       "2   15  8.421442\n",
       "3   16  8.501886\n",
       "4   17  8.157393\n",
       "5   19  8.329672\n",
       "6   20  8.523518\n",
       "7   21  7.858731\n",
       "8   23  8.060452\n",
       "9   29  8.331367\n",
       "10  31  8.381876\n",
       "11  32  7.776227\n",
       "12  33  8.421997\n",
       "13  34  8.205416\n",
       "14  35  8.477636\n",
       "15  37  8.428248\n",
       "16  38  8.161027\n",
       "17  39  8.396740\n",
       "18  40  8.475544\n",
       "19  44  7.963849"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
